{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fb3a78",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfeff7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dependencies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using CUDA.priority in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "println(\"Loading dependencies\")\n",
    "using StatsBase;\n",
    "using JSON;\n",
    "using YAML;\n",
    "using BenchmarkTools;\n",
    "using ProgressMeter;\n",
    "using SQLite;\n",
    "using DataFrames;\n",
    "using ThreadsX;\n",
    "using Flux;\n",
    "using CUDA;\n",
    "include(\"../common/game.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcc54b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training with 8 threads\n"
     ]
    }
   ],
   "source": [
    "println(\"Initializing training with $(Threads.nthreads()) threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b542a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training config from config.yaml\n",
      "Loading model parameters from model.yaml\n"
     ]
    }
   ],
   "source": [
    "println(\"Loading training config from config.yaml\")\n",
    "config = YAML.load_file(\"config.yaml\");\n",
    "println(\"Loading model parameters from model.yaml\")\n",
    "model = YAML.load_file(config[\"model-parameters\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca106eb",
   "metadata": {},
   "source": [
    "# State Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b795acfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state space from statespace.json\n"
     ]
    }
   ],
   "source": [
    "if config[\"statespace\"][\"generate\"]\n",
    "    println(\"Generating state space\")\n",
    "    \n",
    "    println(\"Saving to $(config[\"statespace\"][\"filepath\"])\")\n",
    "    \n",
    "else\n",
    "    println(\"Loading state space from $(config[\"statespace\"][\"filepath\"])\")\n",
    "    STATE_SPACE = Int64[JSON.parsefile(config[\"statespace\"][\"filepath\"],use_mmap=false)...];\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f77cd",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfeca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_games_query = \"\"\"\n",
    "SELECT \n",
    "    games.game_id, winners.username as winner_username, losers.username as loser_username,\n",
    "    winners.is_bot as winner_is_bot, losers.is_bot as loser_is_bot, COUNT(*)/2 as duration\n",
    "FROM games\n",
    "LEFT JOIN players winners\n",
    "    on games.winner_id = winners.player_id\n",
    "LEFT JOIN players losers\n",
    "    on games.loser_id = losers.player_id\n",
    "RIGHT JOIN breaths \n",
    "    on games.game_id = breaths.game_id\n",
    "WHERE\n",
    "    (games.game_id>=$(model[\"data\"][\"epoch-start\"] == -Inf ? 0 : model[\"data\"][\"epoch-start\"]))\n",
    "AND\n",
    "(games.game_id<=$(model[\"data\"][\"epoch-end\"] == Inf ? time() : model[\"data\"][\"epoch-end\"]))\n",
    "AND \n",
    "    ((winner_is_bot=0) OR (loser_is_bot=0))\n",
    "GROUP BY games.game_id\n",
    "\"\"\"\n",
    "#Replace winner/loser IDs with usernames, and indicate whether each is a bot.\n",
    "#Right join the breaths table in order to count the duration of each game.\n",
    "#Games in the training set must have at least one human player, and must occur\n",
    "#before the epoch time cutoff.\n",
    "\n",
    "training_breaths_query = \"\"\"\n",
    "SELECT\n",
    "    training_games.game_id, breaths.state, breaths.action, breaths.is_winner,\n",
    "    (CASE breaths.is_winner\n",
    "        WHEN 1 THEN training_games.winner_is_bot\n",
    "        ELSE training_games.loser_is_bot\n",
    "    END) as is_bot\n",
    "FROM ($(training_games_query)) training_games\n",
    "RIGHT JOIN breaths\n",
    "    on training_games.game_id = breaths.game_id\n",
    "WHERE (is_bot=0)\n",
    "\"\"\"\n",
    "#Use a right join on the `training_games` table to ensure we are only using breaths\n",
    "#from the training set.\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e34b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving gameplay data\n",
      "Data contain 7226 breaths.\n",
      "987 of 2150 possible starting states (45.91%).\n",
      "5361 distinct states of 668884 possible states visited (0.8% of state space).\n"
     ]
    }
   ],
   "source": [
    "println(\"Retrieving gameplay data\")\n",
    "\n",
    "db = eval(Meta.parse(config[\"parless\"][\"database\"]))\n",
    "#Initialize connection to database.\n",
    "\n",
    "training_breaths = DBInterface.execute(db,training_breaths_query) |> DataFrame\n",
    "\n",
    "println(\"\"\"Data contain $(nrow(training_breaths)) breaths.\"\"\")\n",
    "\n",
    "n_starting_states = sum(1 for state in unique(training_breaths[:,\"state\"]) if state in STARTING_STATES)\n",
    "println(\"\"\"$(n_starting_states) of $(length(STARTING_STATES)) possible starting states ($(\n",
    "    round(100*n_starting_states/length(STARTING_STATES),digits=2))%).\"\"\")\n",
    "\n",
    "println(\"\"\"$(length(unique(training_breaths[:,\"state\"]))) distinct states of $(\n",
    "    length(STATE_SPACE)) possible states visited ($(\n",
    "    round(100*length(unique(training_breaths[:,\"state\"]))/length(STATE_SPACE),digits=2)\n",
    "    )% of state space).\"\"\")\n",
    "\n",
    "DBInterface.close!(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90e4172",
   "metadata": {},
   "source": [
    "# PARLESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56b3c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PARLESS reweighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:07\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "parless_strategies = Dict{Int64,Dict{Int64,Float64}}()\n",
    "\n",
    "if model[\"parless\"][\"enabled\"]\n",
    "    println(\"Performing PARLESS reweighting\")  \n",
    "    \n",
    "        @showprogress for state in unique(training_breaths[:,\"state\"])\n",
    "            action_counts = countmap(\n",
    "                training_breaths[training_breaths[:,\"state\"].==state,\"action\"]\n",
    "            )\n",
    "            actions = possible_actions(state)\n",
    "            dirichlet_posterior = Dict(\n",
    "                action => get(action_counts,action,0)+model[\"parless\"][\"prior-pseudocounts\"]/\n",
    "                    length(actions) for action in actions\n",
    "            )\n",
    "            sum_pseudocounts = sum(values(dirichlet_posterior))\n",
    "            categorical_posterior = Dict(\n",
    "                action => pseudocounts/sum_pseudocounts \n",
    "                for (action,pseudocounts) in dirichlet_posterior\n",
    "            )\n",
    "            parless_strategies[state] = categorical_posterior\n",
    "        end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd200e5",
   "metadata": {},
   "source": [
    "# PAWNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10012961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting data for PAWNN\n"
     ]
    }
   ],
   "source": [
    "println(\"Formatting data for PAWNN extrapolation\")\n",
    "training_state_matrix = vcat([\n",
    "    transpose(state_int2vector(state)) for state in unique(training_breaths[:,\"state\"])]...\n",
    "    #Reverse the digits so the first component is breath number; transpose observations \n",
    "    #into row-vectors. Multiply by 1.0 so vectors are float-valued.\n",
    ")\n",
    "\n",
    "training_strategy_matrix = vcat([\n",
    "    transpose(strategy_dict2vector(parless_strategies[state])) \n",
    "    for state in unique(training_breaths[:,\"state\"])]...\n",
    "    #Match strategy vectors to their corresponding states.\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbf70392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PAWNN network\n"
     ]
    }
   ],
   "source": [
    "println(\"Initializing PAWNN network\")\n",
    "\n",
    "Random.seed!(config[\"pawnn\"][\"random-seed\"])\n",
    "\n",
    "pawnn_network = Chain(\n",
    "    (eval(Meta.parse(layer)) for layer in model[\"pawnn\"][\"network-structure\"])...\n",
    ")\n",
    "\n",
    "loss_metric = eval(Meta.parse(model[\"pawnn\"][\"loss-metric\"]))\n",
    "loss(x,y) = loss_metric(pawnn_network(x), y)\n",
    "optimizer = eval(Meta.parse(model[\"pawnn\"][\"optimizer\"]));\n",
    "#Initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0728f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if !isnothing(config[\"pawnn\"][\"initial-weights-file\"])\n",
    "     println(\"Loading network weights from $(config[\"pawnn\"][\"initial-weights-file\"])\")\n",
    "    \n",
    "    loaded_weights = JSON.parsefile(config[\"pawnn\"][\"initial-weights-file\"],use_mmap=false)\n",
    "\n",
    "    reshaped_weights = [\n",
    "        (typeof(layer[1]) <: Vector) ? hcat([col for col in layer]...) : layer\n",
    "        #Convert each layer's parameters from a nested list back into a matrix.\n",
    "        #Single-column matrices will not be formatted as nested lists, so watch out.\n",
    "        for layer in loaded_weights\n",
    "    ]\n",
    "    \n",
    "    Flux.loadparams!(\n",
    "        pawnn_network,\n",
    "        reshaped_weights\n",
    "    )\n",
    "    #Load previously saved parameters.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6684d3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA-capable GPU detected; initializing training process on CPU instead\n"
     ]
    }
   ],
   "source": [
    "processor = cpu\n",
    "if config[\"pawnn\"][\"use-gpu\"]\n",
    "    if CUDA.functional()\n",
    "         println(\"Initializing training process on GPU\")\n",
    "        processor = gpu\n",
    "    else\n",
    "        println(\"No CUDA-capable GPU detected; initializing training process on CPU instead\")\n",
    "    end\n",
    "else\n",
    "    println(\"Initializing training process on CPU\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f6dbc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PAWNN network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:05\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "println(\"Training PAWNN network on $(size(training_strategy_matrix,1)) distinct PARLESS strategies.\")\n",
    "\n",
    "@showprogress for epoch in 1:model[\"pawnn\"][\"n-epochs\"]\n",
    "    Flux.train!(\n",
    "        loss,\n",
    "        Flux.params(pawnn_network),\n",
    "        zip(\n",
    "            eachrow(training_state_matrix),\n",
    "            eachrow(training_strategy_matrix)\n",
    "            #The `eachrow` calls are essentiall; otherwise, `zip` doesn't know\n",
    "            #what to pair up.\n",
    "        ), \n",
    "        optimizer\n",
    "    )\n",
    "end\n",
    "#Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17796ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if !isnothing(config[\"pawnn\"][\"weights-output-file\"])\n",
    "    println(\"Saving network weights to $(config[\"pawnn\"][\"weights-output-file\"])\")\n",
    "    open(config[\"pawnn\"][\"weights-output-file\"],\"w\") do f\n",
    "        JSON.print(f,[layer_params for layer_params in Flux.params(pawnn_network)])\n",
    "        #Parameters are formatted as a vector of matrices. Each matrix is serialized as a list\n",
    "        #of column vectors. \n",
    "    end \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e43dbb",
   "metadata": {},
   "source": [
    "# Transition Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dbb03102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating state-action transition probabilities: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[30m 100%|███████████████████████████████████████████████████| Time: 0:38:35\u001b[39m\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u000008\u001b[39m\u001b[30m  23%|████████████                                       |  ETA: 0:14:55\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "println(\"Calculating state-action transition probabilities: \");\n",
    "\n",
    "progress = Progress(length(STATE_SPACE))\n",
    "\n",
    "transitions = ThreadsX.mapreduce(\n",
    "    state -> begin next!(progress); return Dict(state=>transitionmap(state)) end,\n",
    "    merge,\n",
    "    STATE_SPACE;\n",
    "    init = Dict{Int64, Dict{Int64, Dict{Int64, Float64}}}()\n",
    "    #Must specify initial value as an empty dict.\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06efa50",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bdbe6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function state_reward(s::Int)\n",
    "    if state < 0\n",
    "        return (state == -1) ? +1.0 : -1.0\n",
    "        #If < 0, it's either -1 (a win) or -2 (a loss).\n",
    "    else\n",
    "        return 0.0\n",
    "    end\n",
    "    #Note: values must be specified as floats or else\n",
    "    #nested dicts in the Q-function may assume values to be\n",
    "    #integers.\n",
    "end\n",
    "\n",
    "function state_action_reward(state::Int,action::Int,transition_probabilities::Dict)\n",
    "    \"\"\"This function returns the immediate expected reward of a (state,action) pair,\n",
    "    calculated as the probability-weighted sum of the state-rewards of the possible\n",
    "    successor states.\"\"\"\n",
    "    return sum([p*state_reward(successor) for (successor,p) in transition_probabilities[state][action]])\n",
    "end\n",
    "\n",
    "function initialize_Q_function(transition_probabilities)\n",
    "    \"\"\"This function initializes a state-action value function\n",
    "    such that each (state,action) pair maps to its immediate expected reward.\"\"\"\n",
    "    Q_function = Dict(\n",
    "        state => Dict(\n",
    "            action => state_action_reward(state,action,transition_probabilities)\n",
    "            for action in keys(transitions)\n",
    "        )\n",
    "        for (state,transitions) in transition_probabilities\n",
    "    )\n",
    "end\n",
    "\n",
    "function value_iteration!(Q_function::Dict,transition_probabilities::Dict;discount=0.95)\n",
    "    \"\"\"This function performs a single training episode of value iteration on a given Q-function\n",
    "    dictionary, based on an input transition probability map.\n",
    "\n",
    "    Note: this function mutates the `Q_function` argument.\"\"\"\n",
    "    greedy_choice = (state -> argmax(Q_function[state]))\n",
    "    #Use a greedy policy, in which we choose the action with the highest state-action value for the\n",
    "    #given state.\n",
    "    V_function = Dict(state => Q_function[state][greedy_choice(state)] for state in STATE_SPACE)\n",
    "    #The state-value function assigns each state the value resulting from taking the\n",
    "    #optimal action from that state.\n",
    "\n",
    "    for (state, action_maps) in transition_probabilities\n",
    "        for (action, successors) in action_maps\n",
    "            immediate_reward = state_action_reward(state,action,transition_probabilities)\n",
    "            successor_rewards = sum([p*V_function[successor] for (successor,p) in successors])\n",
    "            Q_function[state][action] = immediate_reward + discount*successor_rewards\n",
    "            #Update each value of the Q-function so that it is equal to the immediate\n",
    "            #state-action reward plus the discounted sum of the state-values\n",
    "            #of the immediate successor states, weighted by their transition probabilities.\n",
    "        end\n",
    "    end\n",
    "    return Q_function\n",
    "\n",
    "end\n",
    "\n",
    "function Q_function_error(Q1::Dict,Q2::Dict;method=:rmse)\n",
    "    \"\"\"This function computes the error between two Q-functions\n",
    "    by comparing all (state,action) pairs. By default, the RMSE\n",
    "    is calculated, however it is also possible to compute the number\n",
    "    of greedy choices that are different.\"\"\"\n",
    "    err = 0\n",
    "    for (state,actions) in Q1\n",
    "        if method == :rmse\n",
    "            for (action,value) in actions\n",
    "                err += (Q1[state][action] - Q2[state][action])^2\n",
    "                #Sum the squared errors for every (state,action) pair.\n",
    "            end\n",
    "        else\n",
    "            err += !(argmax(Q1[state])==argmax(Q2[state]))\n",
    "            #Add 1 to the error for any state for which the highest-value action\n",
    "            #is different between Q1 and Q2.\n",
    "        end\n",
    "    end\n",
    "    if method == :rmse\n",
    "        return sqrt(err)\n",
    "    else\n",
    "        return err\n",
    "    end\n",
    "end\n",
    ";"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 8 Threads 1.8.0",
   "language": "julia",
   "name": "julia-8-threads-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
