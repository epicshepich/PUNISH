{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30c0ae1",
   "metadata": {},
   "source": [
    "# Playing Punish with Reinforcement Learning\n",
    "### Jim Shepich III\n",
    "### Updated: 10 October 2022\n",
    "### Time Required: 23 hours 33  minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ee6cc",
   "metadata": {},
   "source": [
    "# Contents <a id=\"contents\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c231906",
   "metadata": {},
   "source": [
    "- [Import Packages](#import-packages)\n",
    "- [Notebook Settings](#config)\n",
    "- [Representing Game States](#states)\n",
    "- [Representing Actions](#actions)\n",
    "- [Simulating the Game Environment](#environment)\n",
    "- [Enumerating State Space](#state-space)\n",
    "- [Modeling Enemy Strategies](#enemy-strategies)\n",
    "    - [Possible Actions Reweighted by Limited Empirical Strategic Samples (PARLESS)](#parless)\n",
    "    - [PARLESS Augmented With Neural Networks (PAWNN)](#pawnn)\n",
    "- [Enumerating State-Action Transition Probabilities](#transitions)\n",
    "    - [Naïve Transition Probabilities](#naive-transitions)\n",
    "- [Implementation of Value Iteration](#value-iteration)\n",
    "- [Agent Training](#training)\n",
    "    - [Naïve Agent](#naive-agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca0a36",
   "metadata": {},
   "source": [
    "# Import Packages <a name=\"import-packages\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01c60f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Combinatorics\n",
    "using StatsBase\n",
    "using Random\n",
    "using JSON\n",
    "using BenchmarkTools\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d84af6",
   "metadata": {},
   "source": [
    "# Notebook Settings <a name=\"config\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1903c",
   "metadata": {},
   "source": [
    "This section allows a user to configure the setttings of this notebook. For the most part, it will allow you to toggle between generating results or loading them from a file on disk, as well as set model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28783467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Dict{String}} with 3 entries:\n",
       "  \"value-iteration\"          => Dict{String, Dict{String, Any}}(\"naive\"=>Dict(\"…\n",
       "  \"transition-probabilities\" => Dict{String, Dict{String, Any}}(\"naive\"=>Dict(\"…\n",
       "  \"state-space\"              => Dict{String, Any}(\"generate\"=>false, \"filepath\"…"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = Dict(\n",
    "    \"state-space\" => Dict(\n",
    "        \"generate\" => false,\n",
    "        \"filepath\" => \"statespace.json\"\n",
    "    ),\n",
    "    \"transition-probabilities\" => Dict(\n",
    "        \"naive\" => Dict(\"generate\"=>false,\"filepath\"=>\"naive_transitions.json\"),\n",
    "        \"parless\" => Dict(\"generate\"=>true,\"filepath\"=>\"parless_transitions.json\"),\n",
    "        \"pawnn\" => Dict(\"generate\"=>true,\"filepath\"=>\"pawnn_transitions.json\")\n",
    "    ),\n",
    "    \"value-iteration\" => Dict(\n",
    "        \"naive\" => Dict(\"generate\"=>false,\"episodes\"=>0,\"filepath\"=>\"q_naive.json\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7da44",
   "metadata": {},
   "source": [
    "JSON only allows keys to be strings. This is a bit of a problem, since our transition probability maps and state-action value functions are nested dictionaries with integer keys. Rather than converting encoded states and actions to strings when performing lookups, which will be an inefficiency that really adds up, we'll just create a recursive function to parse the keys of these JSON-serialized dictionaries as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8b0626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strkeys2int (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function strkeys2int(d::Dict{String,Any})\n",
    "    \"\"\"This is a function that recursively converts the keys of a `Dict{String,Any}`\n",
    "    and its nested `Dict{String,Any}` values into `Int64` data.\"\"\"\n",
    "    return Dict(parse(Int64,key)=>strkeys2int(value) for (key,value) in d)\n",
    "    #Parse all keys as integers and then call this function on the value.\n",
    "    #If the value is a `Dict{String,Any}`, then its keys will be converted too;\n",
    "    #if not, the value will be left alone.\n",
    "end\n",
    "\n",
    "function strkeys2int(value::Any)\n",
    "    return value\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0888d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 1 entry:\n",
       "  \"naive\" => Any[675.507, 695.864, 699.245, 694.724, 676.924, 653.037, 631.188,…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log = JSON.parsefile(\"training_log.json\",use_mmap=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455169e",
   "metadata": {},
   "source": [
    "# Representing Game States <a id=\"states\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a5bd5",
   "metadata": {},
   "source": [
    "In a standard, two-player game of Punish, the game state consists of the following attributes:\n",
    "\n",
    "- The cards in the two players' hands\n",
    "- The cards that are showing (cards that have been played and the two cards that have been revealed)\n",
    "- The cards that are face-down in the deck (which can potentially be played via the Feint action)\n",
    "- Whether or not each player has already feinted\n",
    "- Whether or not each player is exhausted from using the Punish action\n",
    "- Both players' HP totals\n",
    "- The breath number \n",
    "\n",
    "Although the measure number is also an aspect of the game state, we will exclude it from our modeling because although measure number may have an impact on how a player's attitudes toward taking risks evolves, it does not change the mechanics of the game. Because a game of Punish can theoretically last for an indefinite number of measures (much like Rock-Paper-Scissors), it is necessary that we exclude measure number in order to have a finite state space.\n",
    "\n",
    "We will design our model to support an agent with the limited perspective of a single player. This means that instead of seeing the specific cards in the opponent's hand and the deck, the agent will only be able to see the number of cards in each. Additionally, since the number of face-down cards in the deck can be determined based on feinting status, we don't need to include it in the state. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9df3c",
   "metadata": {},
   "source": [
    "In the next cell, we create a custom structure in which to store a game state. For convenience, we will use `NamedTuple` structures to store the number of each card type in the player's hand, the player's status conditions, enemy's status conditions and hand size, and number of each card type in the discard pile. \n",
    "\n",
    "Victory and loss states will be singleton structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7126d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type PunishState end\n",
    "\n",
    "struct DuelingState <: PunishState\n",
    "    breath::Int64\n",
    "    hand::NamedTuple{(:guard, :rush, :dodge, :strike, :punish), NTuple{5, Int64}}\n",
    "    status::NamedTuple{(:hp, :exhausted, :feinted), Tuple{Int64, Bool, Bool}}\n",
    "    enemy::NamedTuple{(:hp, :hand_size, :exhausted, :feinted), Tuple{Int64, Int64, Bool, Bool}}\n",
    "    discard::NamedTuple{(:guard, :rush, :dodge, :strike, :punish), NTuple{5, Int64}}\n",
    "end \n",
    "\n",
    "struct WinState <: PunishState end\n",
    "struct LossState <: PunishState end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bb09e",
   "metadata": {},
   "source": [
    "Although a struct with `NamedTuple` fields is convenient to work with, it is not a memory-efficient data structure to use in the state-action value function, which we will represent with a lookup table. So, in the next cell, we will implement functions to encode the game state as an integer and decode a game state from such an integer. We will encode a win as -1 and a loss as -2; all dueling states will be encoded as positive integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a529743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decode_state (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode_state(state::DuelingState)\n",
    "    \"\"\"This function encodes a `DuelingState` structure as an integer in which each digit\n",
    "    corresponds to an attribute of the game state.\"\"\"\n",
    "    digit_list = vcat(\n",
    "        [state.breath],\n",
    "        [card for card in state.hand],\n",
    "        [Int(stat) for stat in state.status],\n",
    "        [Int(stat) for stat in state.enemy],\n",
    "        [card for card in state.discard]\n",
    "    )\n",
    "    #Sequentially add each attribute of the game state to a list of digits.\n",
    "    return sum([digit*10^(i-1) for (i, digit) in enumerate(reverse(digit_list))])\n",
    "    #Convert the list of digits into an integer by multiplying each digit by the \n",
    "    #next power of 10 and adding them all together. Reverse the array so that\n",
    "    #the first digit in the array gets multiplied by the largest power of 10\n",
    "    #and becomes the leftmost digit in the resulting integer.\n",
    "end\n",
    "\n",
    "function encode_state(state::WinState)\n",
    "    return -1\n",
    "    #Encode a winning state as -1.\n",
    "end\n",
    "\n",
    "function encode_state(state::LossState)\n",
    "     return -2\n",
    "    #Encode a losing state as -2.\n",
    "end\n",
    "\n",
    "\n",
    "function decode_state(coding::Int64)\n",
    "    \"\"\"This function decodes a game state that has been\n",
    "    encoded as an integer and returns a `DuelingState` structure.\"\"\"\n",
    "    if coding < 0\n",
    "        return [WinState(),LossState()][abs(coding)]\n",
    "    end\n",
    "    digit_list = reverse(digits(coding))\n",
    "    #Convert the encoding into an array of digits, and reverse it so\n",
    "    #that the leftmost digit is the first entry in the array.\n",
    "    state = DuelingState(\n",
    "        digit_list[1],\n",
    "        (\n",
    "            guard=digit_list[2], \n",
    "            rush=digit_list[3], \n",
    "            dodge=digit_list[4], \n",
    "            strike=digit_list[5], \n",
    "            punish=digit_list[6]\n",
    "        ),\n",
    "        (\n",
    "            hp=digit_list[7],\n",
    "            exhausted=Bool(digit_list[8]),\n",
    "            feinted=Bool(digit_list[9])\n",
    "        ),\n",
    "        (\n",
    "            hp=digit_list[10], \n",
    "            hand_size=digit_list[11],\n",
    "            exhausted=Bool(digit_list[12]),\n",
    "            feinted=Bool(digit_list[13])\n",
    "        ),\n",
    "        (\n",
    "            guard=digit_list[14], \n",
    "            rush=digit_list[15], \n",
    "            dodge=digit_list[16], \n",
    "            strike=digit_list[17], \n",
    "            punish=digit_list[18]\n",
    "        )\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb7c74e",
   "metadata": {},
   "source": [
    "Just in case, we will define a dispatch of the `==` operator to compare a pair of `PunishState`s. Turns out that we can easily compare a pair of `PunishState` objects by comparing their integer encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb3f0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.:(==)(x::PunishState, y::PunishState) = encode_state(x) == encode_state(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f9631",
   "metadata": {},
   "source": [
    "# Representing Actions <a id=\"actions\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad938843",
   "metadata": {},
   "source": [
    "Now, we need to decicde how we will represent actions. There are no more than 10 unique actions that can be taken in the game of Punish: play one of any of the 5 card types, or feint with one of those cards. I think that it will be most convenient to work with actions that are represented as `(card::Symbol, feint::Bool)` pairs. However, for memory efficiency, we will encode these pairs as a two-digit integer in which the first digit identifies the card and the second digit indicates whether or not that card is used for a feint.\n",
    "\n",
    "Importantly, if a player is exhausted, then they may not take any actions. We will use the `(:rest,:false)` tuple for this \"action\", which we will encode numerically as `90`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "614ede41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decode_action (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode_action(action::Tuple{Symbol,Bool})\n",
    "    \"\"\"This function takes an action represented as a (card, is_feint) tuple and \n",
    "    encodes it as an integer in which the first digit represents the card used and\n",
    "    the second represents whether or not the action is a feint.\n",
    "    \"\"\"\n",
    "    card_identifiers = (guard=1,rush=2,dodge=3,strike=4,punish=5,rest=9)\n",
    "    #Encode cards as their priority +1; encode a \"rest\"/the nothing card as a 9.\n",
    "    return card_identifiers[action[1]]*10+Int(action[2])\n",
    "end\n",
    "\n",
    "function decode_action(coding::Int)\n",
    "    \"\"\"This function decodes an action encoded as an integer back into a (card,is_feint) tuple.\"\"\"\n",
    "    card_identifiers = Dict(1=>:guard,2=>:rush,3=>:dodge,4=>:strike,5=>:punish,9=>:rest)\n",
    "    card = card_identifiers[digits(coding)[2]]\n",
    "    feint = Bool(digits(coding)[1])\n",
    "    return (card,feint)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a046ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "possible_actions (generic function with 4 methods)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function possible_actions(state::DuelingState)\n",
    "    \"\"\"This function returns an encoded list of the possible actions\n",
    "    that can be taken by the player from a given state.\"\"\"\n",
    "    actions = []\n",
    "    if (state.status.exhausted) || (state.breath==5)\n",
    "        return [encode_action((:rest,false))]\n",
    "        #When the player is exhausted, the only action they can take\n",
    "        #is rest (which by definition does not involve a feint).\n",
    "        #Use Rest without reint as a sentinel action for intermediary\n",
    "        #\"Breath 5\" states.\n",
    "    end\n",
    "    \n",
    "    for (card,count) in pairs(state.hand)\n",
    "        if count == 0 \n",
    "            continue\n",
    "        else\n",
    "            push!(actions,encode_action((card,false)))\n",
    "            #The player can play any card that they hold at least 1 of.\n",
    "            if !state.status.feinted\n",
    "                push!(actions,encode_action((card,true)))\n",
    "                #If they have not already feinted this breath, they also \n",
    "                #have the option of discarding that card to perform a feint.\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return actions\n",
    "end\n",
    "\n",
    "function possible_actions(state::Int)\n",
    "     return possible_actions(decode_state(state))\n",
    "end\n",
    "\n",
    "function possible_actions(state::WinState)\n",
    "     return [90]\n",
    "end\n",
    "\n",
    "function possible_actions(state::LossState)\n",
    "     return [90]\n",
    "end\n",
    "#Use Rest without feint as a sentinel action for Win/Loss states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227dd9d7",
   "metadata": {},
   "source": [
    "# Simulating the Game Environment <a id=\"environment\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463ec0e",
   "metadata": {},
   "source": [
    "In this section, we will create the functions that implement our representation of the overall game environment. In RL problems, the environment is typically modeled as a Markov Decision Process (MDP) — a model in which at any state, an agent can choose from some set of actions that will influence the probabilities of transitioning to different states, and the set of possible actions and transition probabilities from any given state are fixed. In other words, the actions and transition probabilities are a state function rather than a path function.\n",
    "\n",
    "Treating PUNISH as an MDP is a bit of an oversimplification because throughout the course of a Measure, you gain information about what is in the opponent's hand. The most clear example is that if you play a Punish against a Dodge and the enemy does not follow up with a Punish, you know that they do not have a Punish in hand. Additionally, if both players feint and do not use Punish until the last measure, you know with certainty the single card that is in the enemy's hand.\n",
    "\n",
    "Now, if I were to include this information in the game state, there would be less bias in treating the game as an MDP. However, I made the command decision that the benefit of including this information is outweighed by the increase in the size of the state space that would result from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1436b805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ΔHP (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ΔHP(cards::NamedTuple{(:player,:enemy),Tuple{Symbol,Symbol}})\n",
    "    \"\"\"This function computes the change in HP incurred by each player\n",
    "    when a pair of cards is played. Priority is not taken into account here.\"\"\"\n",
    "    if cards.player == cards.enemy\n",
    "        return (player=0, enemy=0)\n",
    "        #No damage is dealt in a clash. \n",
    "    end\n",
    "    \n",
    "    damage_map = Dict(:rush=>1,:strike=>2,:punish=>3)\n",
    "    player_Δ = -get(damage_map,cards.enemy,0) *\n",
    "        #Base damage.\n",
    "        (cards.player==:dodge ? cards.enemy==:rush : 1) +\n",
    "        #Dodging reduces base damage from non-Rush attacks to 0.\n",
    "        (cards.player==:guard ? Int(cards.enemy in keys(damage_map)) : 0)\n",
    "        #Guarding reduces damage from any attacks by 1.\n",
    "    enemy_Δ = -get(damage_map,cards.player,0) *\n",
    "        #Base damage.\n",
    "        (cards.enemy==:dodge ? cards.player==:rush : 1) +\n",
    "        #Dodging reduces base damage from non-Rush attacks to 0.\n",
    "        (cards.enemy==:guard ? Int(cards.player in keys(damage_map)) : 0)\n",
    "        #Guarding reduces damage from any attacks by 1.\n",
    "    \n",
    "    return (player=player_Δ, enemy=enemy_Δ)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae57d0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Symbol, Int64} with 6 entries:\n",
       "  :strike => 3\n",
       "  :dodge  => 2\n",
       "  :guard  => 0\n",
       "  :punish => 4\n",
       "  :rest   => -1\n",
       "  :rush   => 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority = Dict(\n",
    "    :rest => -1,\n",
    "    :guard => 0,\n",
    "    :rush => 1,\n",
    "    :dodge => 2,\n",
    "    :strike => 3,\n",
    "    :punish => 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b822eda",
   "metadata": {},
   "source": [
    "Before we continue, there is a quirk we must introduce into our model. After the fourth Breath of a Measure is resolved, if both players remain above 0 HP, the deck and the discard pile are shuffled together and are used to deal both players back up to 5 cards. This means that the successors of a Breath 4 state will be Breath 1 states (and Win/Loss states). \n",
    "\n",
    "In later sections, we compute transition probabilities for each (state,action) pair. Due to the overwhelmingly large cardinality of the set of possible Breath 4 states (>100k), we found it to be prohibitively inefficient to compute all possible re-dealings for that many Breath 4 states. To remedy this, we will use intermediary \"Breath 5\" states to represent game states after the actions taken in a fourth Breath are resolved but before the cards are redealt. Since status effects are cleared and players heal 1 HP (to a max of 3) between Measures, we will apply this in between Breath 4 and Breath 5 states, which will result in a smaller number of possible Breath 5 states over which redealing probabilities must be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dfc8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breath (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function breath(\n",
    "    state::DuelingState,\n",
    "    picks::NamedTuple{(:player,:enemy),Tuple{Symbol,Symbol}},\n",
    "    feints::NamedTuple,\n",
    "    )\n",
    "    \"\"\"This function takes complete information about one Breath (i.e. the input state,\n",
    "    as well as both players' picked cards and the results of any feints) and returns the\n",
    "    successor state. \n",
    "    \n",
    "    This function is designed to be deterministic and single-valued. To that end, successors\n",
    "    of a fourth breath are returned as a single placeholder whose `breath` field is set to 5;\n",
    "    we will use a different function to compute all possible re-deals for the start of a new\n",
    "    measure.\n",
    "    \"\"\"\n",
    "    plays = (\n",
    "        player=isnothing(feints.player) ? picks.player : feints.player, \n",
    "        enemy=isnothing(feints.enemy) ? picks.enemy : feints.enemy\n",
    "    )\n",
    "    #Track the actual cards that are played \n",
    "    #(i.e. if feinting, the drawn card; otherwise, the picked card).\n",
    "    \n",
    "    successor = DuelingState(\n",
    "        state.breath + 1,\n",
    "        (; [(card,count-Int(card==picks.player)) for (card,count) in pairs(state.hand)]...),\n",
    "        #Whichever card was picked is removed from the hand.\n",
    "        (\n",
    "            hp = state.status.hp+ΔHP(plays).player,\n",
    "            #Compute the change in HP and apply it to the HP total.\n",
    "            exhausted = (plays.player==:punish),\n",
    "            #If the player played Punish this breath they become exhausted.\n",
    "            feinted = (!isnothing(feints.player)||state.status.feinted)\n",
    "            #The player has feinted if they feinted this breath or in a previous breath.\n",
    "        ),\n",
    "        (\n",
    "            hp = state.enemy.hp+ΔHP(plays).enemy, \n",
    "            hand_size = (state.enemy.hand_size-Int(plays.enemy!=:rest)),\n",
    "            #The enemy's hand size decreases by 1 unless they rested after a Punish.\n",
    "            exhausted= (plays.enemy==:punish),\n",
    "            feinted = (!isnothing(feints.enemy)||state.enemy.feinted)\n",
    "        ),\n",
    "        (; [(card,count+sum([picks...,feints...].==card)) \n",
    "            for (card,count) in pairs(state.discard)]...),\n",
    "        #For each card type in the discard pile, increment the count for every\n",
    "        #pick and every feint that matched that type this breath.  \n",
    "    )\n",
    "    \n",
    "    if successor.status.hp <= 0\n",
    "        if successor.enemy.hp <= 0\n",
    "            return priority[plays.player] < priority[plays.enemy] ? WinState() : LossState()\n",
    "            #If both players would be reduced to nonpositive HP this breath, the winner\n",
    "            #is determined by card priority.\n",
    "        else\n",
    "            return LossState()\n",
    "            #If just the player would be reduced to nonpositive HP, it is a loss.\n",
    "        end\n",
    "    elseif successor.enemy.hp <= 0\n",
    "        return WinState()\n",
    "        #If just the enemy would be reduced to nonpositive HP, it is a win.\n",
    "    else\n",
    "        if successor.breath == 5\n",
    "            successor = DuelingState(\n",
    "                successor.breath,\n",
    "                successor.hand,\n",
    "                (hp=min(3,successor.status.hp+1),exhausted=false,feinted=false),\n",
    "                (hp=min(3,successor.enemy.hp+1),hand_size=successor.enemy.hand_size,exhausted=false,feinted=false),\n",
    "                successor.discard\n",
    "            )\n",
    "            #When entering a Breath 5 state, both players heal 1 HP (to a max of 3),\n",
    "            #and status effects (feinted/exhausted) are cleared.\n",
    "        end\n",
    "        \n",
    "        return successor\n",
    "        #If both the player and the enemy have positive HP, then the duel continues.\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c81cf35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "redeal (generic function with 2 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function redeal(state::DuelingState)\n",
    "    \"\"\"This function takes an end-of-measure (\"Breath 5\") state and returns a\n",
    "    dict mapping each possible beginning-of-new-measure state to its\n",
    "    probability of occuring based on a random redealing of cards.\"\"\"\n",
    "    successors = []\n",
    "    for draws in combinations(\n",
    "        vcat([repeat([card],count) for (card, count) in pairs(state.discard)]...),\n",
    "        5-sum(state.hand)\n",
    "    )\n",
    "        #Randomly draw a number of cards equal to the difference between 5 and your \n",
    "        #ending hand size from the cards visible in the discard pile.\n",
    "        \n",
    "        hand = (; [(card,count+sum(draws.==card)) for (card,count) in pairs(state.hand)]...)\n",
    "        #Add the drawn cards to the cards remaining in your hand at the end of the Breath.\n",
    "        \n",
    "        for discards in combinations(\n",
    "            vcat([repeat([card],count-sum(draws.==card)) for (card, count) in pairs(state.discard)]...),\n",
    "            3\n",
    "        )\n",
    "            #Randomly choose 3 cards to go face-up into the discard pile from the cards \n",
    "            #that remain after you've made your draws.\n",
    "            discard = (; [(card,sum(discards.==card)) for (card,count) in pairs(state.discard)]...)\n",
    "            #These three cards replace the old discard pile. The rest of the cards fill the \n",
    "            #enemy's hand and the face-down deck.\n",
    "            \n",
    "            successor = DuelingState(\n",
    "                1, #The first breath of a new measure.\n",
    "                hand,\n",
    "                (hp=state.status.hp,exhausted=false,feinted=false),\n",
    "                #Between measures, each player heals 1HP up to a maximum of 3,\n",
    "                #and status effects are removed.\n",
    "                (hp=state.enemy.hp,hand_size=5,exhausted=false,feinted=false),\n",
    "                discard\n",
    "            )\n",
    "            \n",
    "            push!(successors,encode_state(successor))\n",
    "        end\n",
    "    end\n",
    "    return proportionmap(successors)\n",
    "end\n",
    "\n",
    "\n",
    "function redeal(state::Int)\n",
    "    return redeal(decode_state(state))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ea5c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enemy_states (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function enemy_states(state::DuelingState)\n",
    "    \"\"\"This function takes a DuelingState based on the player's incomplete\n",
    "    information and returns a dict mapping each possible state of the enemy's\n",
    "    incomplete information to a probability based on card counts.\"\"\"\n",
    "    \n",
    "    enemy_states = []\n",
    "    \n",
    "    for enemy_hand in combinations(\n",
    "        vcat([repeat([card],3-state.hand[card]-state.discard[card]) for card in keys(state.discard)]...),\n",
    "        state.enemy.hand_size\n",
    "    )\n",
    "    #The enemy's hand could be any member of the set of all possible combinations of n cards chosen\n",
    "    #from whichever cards the player cannot see, where n is the enemy's hand size. \n",
    "        enemy_state = DuelingState(\n",
    "            state.breath,\n",
    "            (; [(card,sum(enemy_hand.==card)) for card in [:guard,:rush,:dodge,:strike,:punish]]...),\n",
    "            (hp=state.enemy.hp, exhausted=state.enemy.exhausted, feinted=state.enemy.feinted),\n",
    "            (\n",
    "                hp=state.status.hp,\n",
    "                hand_size=sum(state.hand),\n",
    "                exhausted=state.status.exhausted,\n",
    "                feinted=state.status.feinted\n",
    "            ),\n",
    "            state.discard\n",
    "        )\n",
    "        #Breath number, discard, and statuses are all common information. \n",
    "        push!(enemy_states,encode_state(enemy_state))\n",
    "    end\n",
    "    return proportionmap(enemy_states)\n",
    "    #Return normalized value counts of the possible enemy states.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1f74db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transitionmap (generic function with 4 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function transitionmap(state::DuelingState,action::Tuple{Symbol,Bool}; empirical_strategies=Dict())\n",
    "    \"\"\"This function takes a `DuelingState` and an action tuple and\n",
    "    returns a dict mapping all possible successor states to the probability of \n",
    "    that successor resulting from taking the given action from the given state, i.e.\n",
    "    a dict of (successor, transition probability) pairs.\n",
    "    \n",
    "    The `empirical_strategies` keyword argument allows you to pass in a dictionary of \n",
    "    (state, action probability map) pairs corresponding to the enemy's empirically observed\n",
    "    mixed strategies (probability distribution over possible actions). For any states\n",
    "    not in the dictionary, a uniform distribution over all possible actions will be assumed.\n",
    "    \"\"\"\n",
    "    transitions = Dict{Int64,Float64}()\n",
    "    for (enemy_state,p_enemy_state) in enemy_states(state)\n",
    "        #Loop over all possible enemy hands. \n",
    "        enemy_actions = get(\n",
    "            empirical_strategies,\n",
    "            enemy_state,\n",
    "            Dict(enemy_action=>1/length(possible_actions(enemy_state)) \n",
    "                for enemy_action in possible_actions(enemy_state) )\n",
    "        )\n",
    "        #Look up the enemy's state in the empirical strategies dict. If the entry is missing,\n",
    "        #assume a uniform mixed strategy (equal probability of all possible actions).\n",
    "        \n",
    "        decoded_enemy_state = decode_state(enemy_state)\n",
    "        \n",
    "        for (enemy_action,p_enemy_action) in enemy_actions\n",
    "            #Loop over all possible enemy actions.\n",
    "            \n",
    "            deck = vcat([repeat([card],3-(\n",
    "                        state.hand[card]+\n",
    "                        decoded_enemy_state.hand[card]+\n",
    "                        state.discard[card]\n",
    "                        ))\n",
    "                    for card in keys(state.discard)]...)\n",
    "            #With a fixed enemy hand, we have certainty about which cards are in the deck.\n",
    "             \n",
    "            feints = [(player=pf,enemy=ef) for (pf,ef) in zip(\n",
    "                (action[2] ? deck : repeat([nothing],length(deck))),\n",
    "                (decode_action(enemy_action)[2] ? reverse(deck) : repeat([nothing],length(deck))),\n",
    "            )]\n",
    "            #Generate the set of possible outcomes of the feints taken.\n",
    "            if length(feints) == 0\n",
    "                feints = [(player=nothing,enemy=nothing)]\n",
    "            end\n",
    "            \n",
    "            for (feint, p_feint) in proportionmap(feints)\n",
    "                #Loop over the distinct feint outcomces. \n",
    "                picks = (player=action[1],enemy=decode_action(enemy_action)[1])\n",
    "                if state.breath != 5\n",
    "                    successors = Dict(\n",
    "                        encode_state(breath(state,picks,feint))=>1\n",
    "                    )\n",
    "                    #Simulate a Breath using the fixed player and enemy actions and feint outcomes.\n",
    "                else\n",
    "                    successors = redeal(state) \n",
    "                    #If the result is a Breath 5 state, then generate the possible redeals\n",
    "                    #and their probabilities. Otherwise, there is a single successor that\n",
    "                    #occurs with probability 1. \n",
    "                end\n",
    "                for (successor,p_redealt) in successors\n",
    "                    p = p_enemy_state * p_enemy_action * p_feint * p_redealt\n",
    "                    #Multiply all the conditional probabilities to get the overall\n",
    "                    #probability of the successor resulting from the player taking\n",
    "                    #the given action from the given state.\n",
    "                    if successor in keys(transitions)\n",
    "                        transitions[successor] += p\n",
    "                    else\n",
    "                        transitions[successor] = p\n",
    "                    end\n",
    "                    #If this successor has already been mapped out, add the \n",
    "                    #probability from this path to it.\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return transitions\n",
    "end\n",
    "\n",
    "\n",
    "function transitionmap(state::WinState,action::Tuple{Symbol,Bool};kwargs...)\n",
    "    return Dict(-1=>1)\n",
    "end\n",
    "function transitionmap(state::LossState,action::Tuple{Symbol,Bool};kwargs...)\n",
    "    return Dict(-2=>1)\n",
    "end\n",
    "#Win/Loss are \"absorbing states\"; when the game is over, it's over forever.\n",
    "\n",
    "function transitionmap(state::Int,action::Int; kwargs...)\n",
    "     return transitionmap(decode_state(state),decode_action(action);kwargs...)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf5d0d",
   "metadata": {},
   "source": [
    "# Enumerating State Space <a id=\"state-space\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa38b15a",
   "metadata": {},
   "source": [
    "The next thing we have to do as we lay the groundwork is to generate the set of all possible game states. The following facts restrict the state space from the simple Cartesian product of all possible values of each aspect of the game state:\n",
    "- Neither player's HP can be 0 in a non-end state\n",
    "- Neither player's HP can be less than 2 in a Breath 1 state\n",
    "- Neither player can already be exhausted in a Breath 1 state\n",
    "- Neither player can have already feinted in a Breath 1 state\n",
    "- A player's hand size must be 5-(breath#-1) or 5-(breath#-2); the latter can only be true if there is a Punish in the discard pile for that player\n",
    "- Likewise, the number of cards in the discard pile must be 2*(breath#)+(# of feints)-(# of punishes played), where the # of Punishes played is a variable that cannot exceed 2, and must be at least 1 if there are three Punish cards in the discard\n",
    "- For each card type, the sum of the number in hand and the number showing in the discard pile cannot exceed 3.\n",
    "- A player cannot have an HP of 1 unless \n",
    "    - A Strike was used against them (guarded if they started with 2 HP and unguarded if they started with 1)\n",
    "    - A Rush was used against them and not guarded\n",
    "    - A Punish was used against them and guarded \n",
    "\n",
    "It is clear to see that the state space's intension cannot be stated simply. The last rule we have listed in particular shows that when we look into how the cards played affect the possible status conditions, things get pretty complicated.\n",
    "\n",
    "There might be an easier way to generate the set of possible states. The intension of the set of possible Breath 1 states is much simpler than that of the set of all possible states. If we enumerate all possible Breath 1 states, we can simply use the functions we defined in the previous section to generate the set of all possible successor states, i.e. the set of all possible Breath 2 states. Then, we rinse and repeat to get the Breath 3 and Breath 4 states. This is certainly not the most efficient way to go about this, but we only have to do it once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740330c4",
   "metadata": {},
   "source": [
    "We'll start out by generating the possible starting (Measure 1 Breath 1) states. Since both players start with 3 HP, 5 cards in hand, and no status conditions, this boils down to the set of possible combinations of hands and discard piles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d153daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"state-space\"][\"generate\"]\n",
    "    \n",
    "STARTING_STATES = Set{Int64}()\n",
    "hands = Set{NamedTuple}()\n",
    "\n",
    "for draws in (combinations(repeat([:guard,:rush,:dodge,:strike,:punish],3),5))\n",
    "    hand = (; [(card,sum(draws.==card)) for card in [:guard,:rush,:dodge,:strike,:punish]]...)\n",
    "    #Loop over all possible starting hands.\n",
    "    if hand in hands\n",
    "        continue\n",
    "        #The `combinations` function does not account for identical elements, so\n",
    "        #skip any combinations that have already been encountered.\n",
    "    else\n",
    "        push!(hands,hand)\n",
    "        #Track the combinations that have been encountered.\n",
    "    end\n",
    "    \n",
    "    discards = []\n",
    "    for discard_draws in combinations(\n",
    "            vcat([repeat([card],3-count) for (card, count) in pairs(hand)]...),\n",
    "            3\n",
    "        )\n",
    "        #Loop over all possible 3-card discard piles taken from the cards that\n",
    "        #remain after the player's hand has been drawn.\n",
    "        discard = (; [(card,sum(discard_draws.==card)) for card in [:guard,:rush,:dodge,:strike,:punish]]...)\n",
    "        if discard in discards\n",
    "            continue\n",
    "        else\n",
    "            push!(discards,discard)\n",
    "        end\n",
    "        #Likewise, skip discard combinations that have already been encountered.\n",
    "        \n",
    "        starting_state = DuelingState(\n",
    "            1,\n",
    "            hand,\n",
    "            (hp=3, exhausted=false, feinted=false),\n",
    "            (hp=3, hand_size=5, exhausted=false, feinted=false),\n",
    "            discard\n",
    "        )\n",
    "        push!(STARTING_STATES,encode_state(starting_state))\n",
    "         \n",
    "    end\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"$(length(STARTING_STATES)) distinct starting states\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29f0ce",
   "metadata": {},
   "source": [
    "    2150 distinct starting states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a22465e",
   "metadata": {},
   "source": [
    "Now, we'll generate all possible Breath 1 states. Still no status effects and 5 cards in both players' hands, but either or both players can have 2 HP on Breath 1 after the first Measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552c1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"state-space\"][\"generate\"]\n",
    "\n",
    "BREATH1_STATES = union(\n",
    "    STARTING_STATES,\n",
    "    STARTING_STATES .- 0_00000_100_0000_00000,\n",
    "    #Player starts with 2HP\n",
    "    STARTING_STATES .- 0_00000_000_1000_00000,\n",
    "    #Enemy starts with 2HP\n",
    "    STARTING_STATES .- 0_00000_100_1000_00000\n",
    "    #Both start with 2HP\n",
    ")\n",
    "println(\"Breath 1: $(length(BREATH1_STATES)) distinct states\")\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347599f2",
   "metadata": {},
   "source": [
    "    Breath 1: 8600 distinct states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8163a9e5",
   "metadata": {},
   "source": [
    "Now, we have to find the Breath 2-5 states. We will do this by using the `transitionmap` function to find all the possible successors from each state in the previous breath. This will inevitably be very inefficient, but it will get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19ebb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"state-space\"][\"generate\"]\n",
    "\n",
    "STATE_SPACE = Set{Int64}([BREATH1_STATES...])\n",
    "new_states = Set{Int64}([BREATH1_STATES...])\n",
    "\n",
    "for breath in 2:5\n",
    "    successors = Set{Int64}()\n",
    "    for state in new_states\n",
    "        for action in possible_actions(state)\n",
    "            union!(successors, keys(transitionmap(state,action)))\n",
    "            #Loop over all distinct states of the previous breath and \n",
    "            #construct a set of all distinct successors from any state\n",
    "            #in that breath.\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    new_states = successors\n",
    "    println(\"Breath $(breath): $(length(new_states)) distinct states\")\n",
    "    #Print the number of distinct states for each breath number.\n",
    "    \n",
    "    if length(new_states)==0\n",
    "        break\n",
    "    end\n",
    "    \n",
    "    union!(STATE_SPACE,successors)\n",
    "end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5d877",
   "metadata": {},
   "source": [
    "    Breath 2: 169495 distinct states\n",
    "    Breath 3: 259312 distinct states\n",
    "    Breath 4: 212142 distinct states\n",
    "    Breath 5: 19341 distinct states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e1401",
   "metadata": {},
   "source": [
    "This cell took about 20 minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dc2f2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 668884 distinct states\n"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"state-space\"][\"generate\"]\n",
    "    open(CONFIG[\"state-space\"][\"filepath\"],\"w\") do f\n",
    "        JSON.print(f,STATE_SPACE)\n",
    "    end\n",
    "    #If the state space is to be generated, then save the results.\n",
    "else \n",
    "    STATE_SPACE = Set(JSON.parsefile(CONFIG[\"state-space\"][\"filepath\"],use_mmap=false))\n",
    "    #Otherwise, load from disk. The use_mmap keyword must be set to false, otherwise\n",
    "    #the file will remain open in Julia.\n",
    "end\n",
    "println(\"Total: $(length(STATE_SPACE)) distinct states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d0209",
   "metadata": {},
   "source": [
    "# Modeling Enemy Strategies <a id=\"enemy-strategies\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec64605",
   "metadata": {},
   "source": [
    "One of the biases of our current representation of PUNISH is the assumption that at any given state, the enemy will weight each of their possible acitons equally. In actuality, we expect a human player to (on average) avoid taking actions that will lead to imminent defeat. However, human players lack the computational power to estimate expected rewards by considering anything deeper than the immediate Breath. Additionally, attitudes toward risk-taking will also inform a human player's behavior. This is beyond the scope of what we are able to derive from a strictly logical premise. So, we turn to data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f51ff",
   "metadata": {},
   "source": [
    "## Possible Actions Reweighted by Limited Empirical Strategic Samples (PARLESS) <a id=\"parless\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a376a1",
   "metadata": {},
   "source": [
    "In this section, I present a method for using real game data to reweight the enemy's mixed strategies (i.e. probability distribution over possible actions) which I call **\"Possible Actions Reweighted by Limited Empirical Strategic Samples\" (PARLESS)**. In this method, we will use the empirical distribution of actions taken from a given state by real players as the \"evidence\" term in Bayes' rule to reweight the parameters of a multinomial probability distribution, which we use to represent the mixed strategy. We will use a Dirichlet prior with equal probabilities, as it is the conjugate prior of the multinomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63964356",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/44494/why-is-the-dirichlet-distribution-the-prior-for-the-multinomial-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1a1c52",
   "metadata": {},
   "source": [
    "## PARLESS Augmented With Neural Networks (PAWNN) <a id=\"pawnn\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ca74cb",
   "metadata": {},
   "source": [
    "PUNISH has a small yet dedicated player base. However, with hundreds of thousands of game states, we simply do not have empirical strategy data for every possible action. However, we may be able to extrapolate from the states that we do have using a deep neural network model. Here, we will experiment with using neural networks trained on the (state ↦ mixed strategy) set generated by the basic PARLESS method to extrapolate mixed strategies for states for which we lack data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f5b89",
   "metadata": {},
   "source": [
    "# Enumerating State-Action Transition Probabilities <a id=\"transitions\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ab7aab",
   "metadata": {},
   "source": [
    "Although we have the `transitionmap` function to generate the transition probabilities for any given state-action pair, it will significantly speed up the value iteration algorithm if we pre-compile the transition probabilities.\n",
    "\n",
    "Note: we will need to generate a separate transition probability map for all three models of enemy strategies (Naïve, PARLESS, and PAWNN).\n",
    "\n",
    "Before we included intermediary \"Breath 5\" states, extrapolation from benchmark experiments indicated that generating transition probabilities for each (state,action) pair would take somewhere around 42 hours. With Breath 5 states between non-terminal Breath 4 results and redeals, this computation takes around a half hour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cbe53",
   "metadata": {},
   "source": [
    "## Naïve Transition Probabilities <a id=\"naive-transitions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797f119",
   "metadata": {},
   "source": [
    "This next cell will compute transition probabilities under the Naïve model of enemy strategies, which is just a fancy way of referring to the assumption that the enemy is equally probable to choose any of their possible actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bf8c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{Int64, Dict{Int64}}\n"
     ]
    }
   ],
   "source": [
    "if CONFIG[\"transition-probabilities\"][\"naive\"][\"generate\"]\n",
    "    NAIVE_TRANSITIONS = Dict( \n",
    "        state => Dict(\n",
    "            action => transitionmap(state,action) \n",
    "            for action in possible_actions(state)\n",
    "        )\n",
    "        for state in STATE_SPACE\n",
    "    )\n",
    "    open(CONFIG[\"transition-probabilities\"][\"naive\"][\"filepath\"],\"w\") do f\n",
    "        JSON.print(f,NAIVE_TRANSITIONS)\n",
    "    end\n",
    "    #Generate transition map and save results.\n",
    "else \n",
    "    NAIVE_TRANSITIONS = strkeys2int(\n",
    "        JSON.parsefile(CONFIG[\"transition-probabilities\"][\"naive\"][\"filepath\"],use_mmap=false)\n",
    "    )\n",
    "    #Load results from disk.\n",
    "end\n",
    "println(typeof(NAIVE_TRANSITIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdeb76",
   "metadata": {},
   "source": [
    "This cell took about 35 minutes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd363c3",
   "metadata": {},
   "source": [
    "## PARLESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea73cf",
   "metadata": {},
   "source": [
    "## PAWNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254a242",
   "metadata": {},
   "source": [
    "# Implementation of Value Iteration <a id=\"value-iteration\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d81016",
   "metadata": {},
   "source": [
    "In this section, we will implement the value iteration algorithm  (and its accessory functions), which we will use to train our agents. Value iteration is an offline reinforcement learning algorithm which applies dynamic programming to an MDP-representation of a game to generate a \"state-action value\" function (also known as a Q-function), which assigns relative values to taking a given action from a given state for every possible (state,action) pairing. [This video](https://youtu.be/4KGC_3GWuPY) does an excellent job showing how the algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282e01f",
   "metadata": {},
   "source": [
    "Reinforcement learning algorithms require a state-action reward function, which assigns quantitative rewards to each (state,action) pair. If we want to incentivize certain kinds of gameplay, we might customize the values in these functions. However, we will just stick with the basic state-action reward function, in which the reward for taking some action at a given state is just the expected value of the state-rewards of all the successors of that action (i.e. the sum of the state rewards of the successors, weighted by their probabilities of resulting from the action). \n",
    "\n",
    "We will also keep our state reward function pretty simple: a WinState is +1, a LossState is -1, and any DuelingState is 0. If we wanted to incentivize the agent to keep games quick (i.e. penalize it for dragging the game out), we might assign a slight negative value to DuelingStates, but I believe that the inherent risk of playing the game is enough of a driving force to keep things short and sweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ecee2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_action_reward (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function state_reward(s::Int)\n",
    "    return get(Dict(-2=>-1.0,-1=>+1.0),s,0.0)\n",
    "    #Faster than wasting time decoding the state.\n",
    "    #Note: values must be specified as floats or else\n",
    "    #nested dicts in the Q-function may assume values to be\n",
    "    #integers.\n",
    "end\n",
    "\n",
    "function state_action_reward(state::Int,action::Int,transition_probabilities::Dict)\n",
    "    \"\"\"This function returns the immediate expected reward of a (state,action) pair, \n",
    "    calculated as the probability-weighted sum of the state-rewards of the possible\n",
    "    successor states.\"\"\"\n",
    "    return sum([p*state_reward(successor) for (successor,p) in transition_probabilities[state][action]])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add3462",
   "metadata": {},
   "source": [
    "We will initialize the blank state-action function such that the value of any given (state,action) pair is equal to the immediate expected state-action reward, as defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e11b39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initialize_Q_function (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function initialize_Q_function(transition_probabilities)\n",
    "    \"\"\"This function initializes a state-action value function\n",
    "    such that each (state,action) pair maps to its immediate expected reward.\"\"\"\n",
    "    Q_function = Dict(\n",
    "        state => Dict(\n",
    "            action => state_action_reward(state,action,transition_probabilities)\n",
    "            for action in keys(transitions)\n",
    "        )\n",
    "        for (state,transitions) in transition_probabilities\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4603c0e",
   "metadata": {},
   "source": [
    "Now, we have all the pieces we need to implement value iteration. The value iteration algorithm itself is pretty simple. It really consists of two basic steps:\n",
    "\n",
    "1. Compute the \"state-value\" function (also known as the V-function) which assigns values to states themselves rather than (state,action) pairs. The value assigned is simply the Q-function value resulting from taking the optimal action (i.e. argmax of the Q-function for that state) from that state.\n",
    "2. Update the Q-function; the new value of a given (state,action) pair is equal to the immediate state-action reward plus the \"discounted\" (scaled by $0<\\gamma<1$) probability-weighted sum of the successors' V-function values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51fce523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value_iteration! (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function value_iteration!(Q_function::Dict,transition_probabilities::Dict;discount=0.95) \n",
    "    \"\"\"This function performs a single training episode of value iteration on a given Q-function\n",
    "    dictionary, based on an input transition probability map.\n",
    "    \n",
    "    Note: this function mutates the `Q_function` argument.\"\"\"\n",
    "    greedy_choice = (state -> argmax(Q_function[state]))\n",
    "    #Use a greedy policy, in which we choose the action with the highest state-action value for the\n",
    "    #given state.\n",
    "    V_function = Dict(state => Q_function[state][greedy_choice(state)] for state in STATE_SPACE)\n",
    "    #The state-value function assigns each state the value resulting from taking the \n",
    "    #optimal action from that state.\n",
    "\n",
    "    for (state, action_maps) in transition_probabilities\n",
    "        for (action, successors) in action_maps\n",
    "            immediate_reward = state_action_reward(state,action,transition_probabilities)\n",
    "            successor_rewards = sum([p*V_function[successor] for (successor,p) in successors])\n",
    "            Q_function[state][action] = immediate_reward + discount*successor_rewards\n",
    "            #Update each value of the Q-function so that it is equal to the immediate\n",
    "            #state-action reward plus the discounted sum of the state-values\n",
    "            #of the immediate successor states, weighted by their transition probabilities.\n",
    "        end\n",
    "    end\n",
    "    return Q_function\n",
    "                     \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e39b3f",
   "metadata": {},
   "source": [
    "Finally, we will need to create a function to measure the change between two Q-functions so that we can measure the convergence of our training. We will do this by computing the root-mean-square error over all possible (state,action) pairs between two Q-functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c691fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q_function_error (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Q_function_error(Q1::Dict,Q2::Dict)\n",
    "    \"\"\"This function computes the RMSE over all\n",
    "    (state,action) pairs between two Q-functions.\"\"\"\n",
    "    err = 0\n",
    "    for (state,actions) in Q1\n",
    "        for (action,value) in actions\n",
    "            err += (Q1[state][action] - Q2[state][action])^2\n",
    "            #Sum the squared errors for every (state,action) pair.\n",
    "        end\n",
    "    end\n",
    "    return sqrt(err)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a4c648",
   "metadata": {},
   "source": [
    "# Agent Training <a id=\"training\"></a>\n",
    "### [↑ Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328493d",
   "metadata": {},
   "source": [
    "In this section, we will apply value iteration to train our agents. We will design this Notebook such that if a specified number of training episodes is found to be insufficient, we can pick up where we left off rather than starting training over from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbcb5e",
   "metadata": {},
   "source": [
    "## Naïve Agent <a id=\"naive-agent\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e49707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Dict{Int64, Float64}} with 668884 entries:\n",
       "  310200300330123030 => Dict(11=>-0.952812, 10=>12.4745, 31=>-1.15578, 30=>13.5…\n",
       "  511001300210021222 => Dict(90=>15.0316)\n",
       "  210300301140121022 => Dict(10=>5.31734, 30=>12.9174)\n",
       "  102012300350000300 => Dict(51=>11.1003, 50=>15.6902, 41=>10.4096, 21=>11.4714…\n",
       "  401020201220131213 => Dict(20=>13.3267, 40=>14.9711)\n",
       "  301110301330130222 => Dict(20=>-5.0521, 30=>5.42679, 40=>-1.55826)\n",
       "  300111300331122202 => Dict(51=>15.0781, 50=>19.8875, 41=>18.8875, 31=>18.8875…\n",
       "  300111211331023012 => Dict(90=>11.7682)\n",
       "  201210301340112121 => Dict(20=>-4.2145, 30=>7.01121, 40=>-4.33004)\n",
       "  300111110131103122 => Dict(90=>17.4737)\n",
       "  210003200240010130 => Dict(51=>12.7017, 50=>16.3388, 11=>11.1431, 10=>14.653)\n",
       "  220011200140010112 => Dict(51=>14.9706, 50=>6.04144, 41=>13.4759, 11=>14.5631…\n",
       "  401100201330032211 => Dict(20=>-19.8875, 30=>9.10219)\n",
       "  300111200130132021 => Dict(51=>18.1634, 50=>11.8258, 41=>16.9036, 31=>18.0665…\n",
       "  301011100130111222 => Dict(51=>11.595, 50=>3.4369, 41=>9.95559, 21=>4.4485, 2…\n",
       "  401020200331120303 => Dict(41=>12.3752, 21=>12.6348, 20=>11.9572, 40=>16.4689)\n",
       "  400101301230023112 => Dict(50=>17.6443, 30=>12.3016)\n",
       "  300120211331131113 => Dict(90=>12.4234)\n",
       "  401020301330002213 => Dict(20=>10.3025, 40=>10.02)\n",
       "  430000210321001133 => Dict(90=>10.3228)\n",
       "  211011210140012101 => Dict(90=>-0.775392)\n",
       "  400101101130030132 => Dict(50=>-9.69685, 30=>-9.80323)\n",
       "  200103100240021200 => Dict(51=>-16.2509, 50=>-11.9325, 31=>-16.4454, 30=>-15.…\n",
       "  420000110131113203 => Dict(90=>1.0531)\n",
       "  402000311221030232 => Dict(90=>8.46695)\n",
       "  ⋮                  => ⋮"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CONFIG[\"value-iteration\"][\"naive\"][\"generate\"]\n",
    "    Q_Naive = initialize_Q_function(NAIVE_TRANSITIONS)\n",
    "    #If generating from scratch, initialize the Q-function with \n",
    "    #immediate expected rewards.\n",
    "    training_log[\"naive\"] = []\n",
    "else \n",
    "    Q_Naive = strkeys2int(\n",
    "        JSON.parsefile(CONFIG[\"value-iteration\"][\"naive\"][\"filepath\"],use_mmap=false)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ae10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 101: RMSE=5.35349066338031\n",
      "Episode 102: RMSE=5.085831529477704\n",
      "Episode 103: RMSE=4.831545750031296\n",
      "Episode 104: RMSE=4.589975301251026\n",
      "Episode 105: RMSE=4.360494400860289\n",
      "Episode 106: RMSE=4.142502842483667\n",
      "Episode 107: RMSE=3.9353987138951454\n",
      "Episode 108: RMSE=3.7386369725225195\n",
      "Episode 109: RMSE=3.551706974497102\n",
      "Episode 110: RMSE=3.3741245156234045\n",
      "Episode 111: RMSE=3.205423230547698\n",
      "Episode 112: RMSE=3.0451556966146307\n",
      "Episode 113: RMSE=2.892901366661692\n",
      "Episode 114: RMSE=2.7482614103752026\n",
      "Episode 115: RMSE=2.6108518261912987\n",
      "Episode 116: RMSE=2.480311304589201\n",
      "Episode 117: RMSE=2.3562968651385603\n",
      "Episode 118: RMSE=2.2384826828463544\n",
      "Episode 119: RMSE=2.126559037979792\n",
      "Episode 120: RMSE=2.0202316300885625\n",
      "Episode 121: RMSE=1.9192205620544929\n",
      "Episode 122: RMSE=1.8232597609562056\n",
      "Episode 123: RMSE=1.732096940797657\n",
      "Episode 124: RMSE=1.6454924158456163\n",
      "Episode 125: RMSE=1.5632183619595168\n"
     ]
    }
   ],
   "source": [
    "for i in (1:CONFIG[\"value-iteration\"][\"naive\"][\"episodes\"]).+length(training_log[\"naive\"])\n",
    "    #Start training from the next episode over the last one logged.\n",
    "    Q_Naive_old = deepcopy(Q_Naive)\n",
    "    #Copy the current Q-function before training for comparison. \n",
    "    Q_Naive = value_iteration!(Q_Naive,NAIVE_TRANSITIONS)\n",
    "    #Run one episode of value iteration.\n",
    "    err = Q_function_error(Q_Naive,Q_Naive_old)\n",
    "    #Compute the RMSE for the before and after Q-functions to\n",
    "    #check convergence.\n",
    "    push!(training_log[\"naive\"],err)\n",
    "    #Record the RMSE value in the log.\n",
    "    println(\"Episode $(i): RMSE=$(err)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "226b3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"value-iteration\"][\"naive\"][\"episodes\"] > 0\n",
    "    open(CONFIG[\"value-iteration\"][\"naive\"][\"filepath\"],\"w\") do f\n",
    "        JSON.print(f,Q_Naive)\n",
    "    end\n",
    "    open(\"training_log.json\",\"w\") do f\n",
    "        JSON.print(f,training_log)\n",
    "    end\n",
    "    #If training was performed, save the trained Q-function and the\n",
    "    #logged RMSE values.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d54211c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip840\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip840)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip841\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip840)\" d=\"\n",
       "M235.283 1423.18 L2352.76 1423.18 L2352.76 123.472 L235.283 123.472  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip842\">\n",
       "    <rect x=\"235\" y=\"123\" width=\"2118\" height=\"1301\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.102,1423.18 279.102,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  601.298,1423.18 601.298,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  923.494,1423.18 923.494,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1245.69,1423.18 1245.69,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1567.89,1423.18 1567.89,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1890.08,1423.18 1890.08,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2212.28,1423.18 2212.28,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.102,1423.18 279.102,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  601.298,1423.18 601.298,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  923.494,1423.18 923.494,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1245.69,1423.18 1245.69,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1567.89,1423.18 1567.89,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1890.08,1423.18 1890.08,1404.28 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2212.28,1423.18 2212.28,1404.28 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M279.102 1454.1 Q275.49 1454.1 273.662 1457.66 Q271.856 1461.2 271.856 1468.33 Q271.856 1475.44 273.662 1479.01 Q275.49 1482.55 279.102 1482.55 Q282.736 1482.55 284.541 1479.01 Q286.37 1475.44 286.37 1468.33 Q286.37 1461.2 284.541 1457.66 Q282.736 1454.1 279.102 1454.1 M279.102 1450.39 Q284.912 1450.39 287.967 1455 Q291.046 1459.58 291.046 1468.33 Q291.046 1477.06 287.967 1481.67 Q284.912 1486.25 279.102 1486.25 Q273.291 1486.25 270.213 1481.67 Q267.157 1477.06 267.157 1468.33 Q267.157 1459.58 270.213 1455 Q273.291 1450.39 279.102 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M580.071 1481.64 L596.39 1481.64 L596.39 1485.58 L574.446 1485.58 L574.446 1481.64 Q577.108 1478.89 581.691 1474.26 Q586.298 1469.61 587.478 1468.27 Q589.724 1465.74 590.603 1464.01 Q591.506 1462.25 591.506 1460.56 Q591.506 1457.8 589.562 1456.07 Q587.64 1454.33 584.538 1454.33 Q582.339 1454.33 579.886 1455.09 Q577.455 1455.86 574.677 1457.41 L574.677 1452.69 Q577.502 1451.55 579.955 1450.97 Q582.409 1450.39 584.446 1450.39 Q589.816 1450.39 593.011 1453.08 Q596.205 1455.77 596.205 1460.26 Q596.205 1462.39 595.395 1464.31 Q594.608 1466.2 592.501 1468.8 Q591.923 1469.47 588.821 1472.69 Q585.719 1475.88 580.071 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M616.205 1454.1 Q612.594 1454.1 610.765 1457.66 Q608.96 1461.2 608.96 1468.33 Q608.96 1475.44 610.765 1479.01 Q612.594 1482.55 616.205 1482.55 Q619.839 1482.55 621.645 1479.01 Q623.473 1475.44 623.473 1468.33 Q623.473 1461.2 621.645 1457.66 Q619.839 1454.1 616.205 1454.1 M616.205 1450.39 Q622.015 1450.39 625.071 1455 Q628.149 1459.58 628.149 1468.33 Q628.149 1477.06 625.071 1481.67 Q622.015 1486.25 616.205 1486.25 Q610.395 1486.25 607.316 1481.67 Q604.261 1477.06 604.261 1468.33 Q604.261 1459.58 607.316 1455 Q610.395 1450.39 616.205 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M911.665 1455.09 L899.86 1473.54 L911.665 1473.54 L911.665 1455.09 M910.438 1451.02 L916.318 1451.02 L916.318 1473.54 L921.248 1473.54 L921.248 1477.43 L916.318 1477.43 L916.318 1485.58 L911.665 1485.58 L911.665 1477.43 L896.063 1477.43 L896.063 1472.92 L910.438 1451.02 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M938.98 1454.1 Q935.369 1454.1 933.54 1457.66 Q931.735 1461.2 931.735 1468.33 Q931.735 1475.44 933.54 1479.01 Q935.369 1482.55 938.98 1482.55 Q942.614 1482.55 944.42 1479.01 Q946.248 1475.44 946.248 1468.33 Q946.248 1461.2 944.42 1457.66 Q942.614 1454.1 938.98 1454.1 M938.98 1450.39 Q944.79 1450.39 947.846 1455 Q950.924 1459.58 950.924 1468.33 Q950.924 1477.06 947.846 1481.67 Q944.79 1486.25 938.98 1486.25 Q933.17 1486.25 930.091 1481.67 Q927.035 1477.06 927.035 1468.33 Q927.035 1459.58 930.091 1455 Q933.17 1450.39 938.98 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1231.1 1466.44 Q1227.95 1466.44 1226.1 1468.59 Q1224.27 1470.74 1224.27 1474.49 Q1224.27 1478.22 1226.1 1480.39 Q1227.95 1482.55 1231.1 1482.55 Q1234.24 1482.55 1236.07 1480.39 Q1237.92 1478.22 1237.92 1474.49 Q1237.92 1470.74 1236.07 1468.59 Q1234.24 1466.44 1231.1 1466.44 M1240.38 1451.78 L1240.38 1456.04 Q1238.62 1455.21 1236.81 1454.77 Q1235.03 1454.33 1233.27 1454.33 Q1228.64 1454.33 1226.19 1457.45 Q1223.76 1460.58 1223.41 1466.9 Q1224.78 1464.89 1226.84 1463.82 Q1228.9 1462.73 1231.37 1462.73 Q1236.58 1462.73 1239.59 1465.9 Q1242.62 1469.05 1242.62 1474.49 Q1242.62 1479.82 1239.47 1483.03 Q1236.33 1486.25 1231.1 1486.25 Q1225.1 1486.25 1221.93 1481.67 Q1218.76 1477.06 1218.76 1468.33 Q1218.76 1460.14 1222.65 1455.28 Q1226.53 1450.39 1233.09 1450.39 Q1234.85 1450.39 1236.63 1450.74 Q1238.43 1451.09 1240.38 1451.78 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1260.68 1454.1 Q1257.07 1454.1 1255.24 1457.66 Q1253.43 1461.2 1253.43 1468.33 Q1253.43 1475.44 1255.24 1479.01 Q1257.07 1482.55 1260.68 1482.55 Q1264.31 1482.55 1266.12 1479.01 Q1267.95 1475.44 1267.95 1468.33 Q1267.95 1461.2 1266.12 1457.66 Q1264.31 1454.1 1260.68 1454.1 M1260.68 1450.39 Q1266.49 1450.39 1269.54 1455 Q1272.62 1459.58 1272.62 1468.33 Q1272.62 1477.06 1269.54 1481.67 Q1266.49 1486.25 1260.68 1486.25 Q1254.87 1486.25 1251.79 1481.67 Q1248.73 1477.06 1248.73 1468.33 Q1248.73 1459.58 1251.79 1455 Q1254.87 1450.39 1260.68 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1552.76 1469.17 Q1549.43 1469.17 1547.5 1470.95 Q1545.61 1472.73 1545.61 1475.86 Q1545.61 1478.98 1547.5 1480.77 Q1549.43 1482.55 1552.76 1482.55 Q1556.09 1482.55 1558.01 1480.77 Q1559.93 1478.96 1559.93 1475.86 Q1559.93 1472.73 1558.01 1470.95 Q1556.12 1469.17 1552.76 1469.17 M1548.08 1467.18 Q1545.07 1466.44 1543.38 1464.38 Q1541.72 1462.32 1541.72 1459.35 Q1541.72 1455.21 1544.66 1452.8 Q1547.62 1450.39 1552.76 1450.39 Q1557.92 1450.39 1560.86 1452.8 Q1563.8 1455.21 1563.8 1459.35 Q1563.8 1462.32 1562.11 1464.38 Q1560.44 1466.44 1557.46 1467.18 Q1560.84 1467.96 1562.71 1470.26 Q1564.61 1472.55 1564.61 1475.86 Q1564.61 1480.88 1561.53 1483.57 Q1558.48 1486.25 1552.76 1486.25 Q1547.04 1486.25 1543.96 1483.57 Q1540.91 1480.88 1540.91 1475.86 Q1540.91 1472.55 1542.81 1470.26 Q1544.7 1467.96 1548.08 1467.18 M1546.37 1459.79 Q1546.37 1462.48 1548.04 1463.98 Q1549.73 1465.49 1552.76 1465.49 Q1555.77 1465.49 1557.46 1463.98 Q1559.17 1462.48 1559.17 1459.79 Q1559.17 1457.11 1557.46 1455.6 Q1555.77 1454.1 1552.76 1454.1 Q1549.73 1454.1 1548.04 1455.6 Q1546.37 1457.11 1546.37 1459.79 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1582.92 1454.1 Q1579.31 1454.1 1577.48 1457.66 Q1575.68 1461.2 1575.68 1468.33 Q1575.68 1475.44 1577.48 1479.01 Q1579.31 1482.55 1582.92 1482.55 Q1586.55 1482.55 1588.36 1479.01 Q1590.19 1475.44 1590.19 1468.33 Q1590.19 1461.2 1588.36 1457.66 Q1586.55 1454.1 1582.92 1454.1 M1582.92 1450.39 Q1588.73 1450.39 1591.79 1455 Q1594.87 1459.58 1594.87 1468.33 Q1594.87 1477.06 1591.79 1481.67 Q1588.73 1486.25 1582.92 1486.25 Q1577.11 1486.25 1574.03 1481.67 Q1570.98 1477.06 1570.98 1468.33 Q1570.98 1459.58 1574.03 1455 Q1577.11 1450.39 1582.92 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1849.69 1481.64 L1857.33 1481.64 L1857.33 1455.28 L1849.02 1456.95 L1849.02 1452.69 L1857.28 1451.02 L1861.96 1451.02 L1861.96 1481.64 L1869.6 1481.64 L1869.6 1485.58 L1849.69 1485.58 L1849.69 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1889.04 1454.1 Q1885.43 1454.1 1883.6 1457.66 Q1881.8 1461.2 1881.8 1468.33 Q1881.8 1475.44 1883.6 1479.01 Q1885.43 1482.55 1889.04 1482.55 Q1892.67 1482.55 1894.48 1479.01 Q1896.31 1475.44 1896.31 1468.33 Q1896.31 1461.2 1894.48 1457.66 Q1892.67 1454.1 1889.04 1454.1 M1889.04 1450.39 Q1894.85 1450.39 1897.91 1455 Q1900.98 1459.58 1900.98 1468.33 Q1900.98 1477.06 1897.91 1481.67 Q1894.85 1486.25 1889.04 1486.25 Q1883.23 1486.25 1880.15 1481.67 Q1877.1 1477.06 1877.1 1468.33 Q1877.1 1459.58 1880.15 1455 Q1883.23 1450.39 1889.04 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1919.2 1454.1 Q1915.59 1454.1 1913.76 1457.66 Q1911.96 1461.2 1911.96 1468.33 Q1911.96 1475.44 1913.76 1479.01 Q1915.59 1482.55 1919.2 1482.55 Q1922.84 1482.55 1924.64 1479.01 Q1926.47 1475.44 1926.47 1468.33 Q1926.47 1461.2 1924.64 1457.66 Q1922.84 1454.1 1919.2 1454.1 M1919.2 1450.39 Q1925.01 1450.39 1928.07 1455 Q1931.15 1459.58 1931.15 1468.33 Q1931.15 1477.06 1928.07 1481.67 Q1925.01 1486.25 1919.2 1486.25 Q1913.39 1486.25 1910.31 1481.67 Q1907.26 1477.06 1907.26 1468.33 Q1907.26 1459.58 1910.31 1455 Q1913.39 1450.39 1919.2 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M2171.89 1481.64 L2179.52 1481.64 L2179.52 1455.28 L2171.21 1456.95 L2171.21 1452.69 L2179.48 1451.02 L2184.15 1451.02 L2184.15 1481.64 L2191.79 1481.64 L2191.79 1485.58 L2171.89 1485.58 L2171.89 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M2205.26 1481.64 L2221.58 1481.64 L2221.58 1485.58 L2199.64 1485.58 L2199.64 1481.64 Q2202.3 1478.89 2206.88 1474.26 Q2211.49 1469.61 2212.67 1468.27 Q2214.92 1465.74 2215.8 1464.01 Q2216.7 1462.25 2216.7 1460.56 Q2216.7 1457.8 2214.76 1456.07 Q2212.83 1454.33 2209.73 1454.33 Q2207.53 1454.33 2205.08 1455.09 Q2202.65 1455.86 2199.87 1457.41 L2199.87 1452.69 Q2202.7 1451.55 2205.15 1450.97 Q2207.6 1450.39 2209.64 1450.39 Q2215.01 1450.39 2218.2 1453.08 Q2221.4 1455.77 2221.4 1460.26 Q2221.4 1462.39 2220.59 1464.31 Q2219.8 1466.2 2217.7 1468.8 Q2217.12 1469.47 2214.01 1472.69 Q2210.91 1475.88 2205.26 1481.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M2241.4 1454.1 Q2237.79 1454.1 2235.96 1457.66 Q2234.15 1461.2 2234.15 1468.33 Q2234.15 1475.44 2235.96 1479.01 Q2237.79 1482.55 2241.4 1482.55 Q2245.03 1482.55 2246.84 1479.01 Q2248.67 1475.44 2248.67 1468.33 Q2248.67 1461.2 2246.84 1457.66 Q2245.03 1454.1 2241.4 1454.1 M2241.4 1450.39 Q2247.21 1450.39 2250.26 1455 Q2253.34 1459.58 2253.34 1468.33 Q2253.34 1477.06 2250.26 1481.67 Q2247.21 1486.25 2241.4 1486.25 Q2235.59 1486.25 2232.51 1481.67 Q2229.45 1477.06 2229.45 1468.33 Q2229.45 1459.58 2232.51 1455 Q2235.59 1450.39 2241.4 1450.39 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1028.7 1520.52 L1068.9 1520.52 L1068.9 1525.93 L1052.03 1525.93 L1052.03 1568.04 L1045.57 1568.04 L1045.57 1525.93 L1028.7 1525.93 L1028.7 1520.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1085.92 1537.87 Q1084.94 1537.3 1083.76 1537.04 Q1082.61 1536.76 1081.21 1536.76 Q1076.25 1536.76 1073.57 1540 Q1070.93 1543.22 1070.93 1549.27 L1070.93 1568.04 L1065.04 1568.04 L1065.04 1532.4 L1070.93 1532.4 L1070.93 1537.93 Q1072.78 1534.69 1075.74 1533.13 Q1078.7 1531.54 1082.93 1531.54 Q1083.54 1531.54 1084.27 1531.63 Q1085 1531.7 1085.89 1531.85 L1085.92 1537.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1108.27 1550.12 Q1101.17 1550.12 1098.43 1551.75 Q1095.7 1553.37 1095.7 1557.29 Q1095.7 1560.4 1097.73 1562.25 Q1099.8 1564.07 1103.33 1564.07 Q1108.2 1564.07 1111.13 1560.63 Q1114.09 1557.16 1114.09 1551.43 L1114.09 1550.12 L1108.27 1550.12 M1119.95 1547.71 L1119.95 1568.04 L1114.09 1568.04 L1114.09 1562.63 Q1112.09 1565.88 1109.1 1567.44 Q1106.1 1568.97 1101.78 1568.97 Q1096.3 1568.97 1093.05 1565.91 Q1089.84 1562.82 1089.84 1557.67 Q1089.84 1551.65 1093.85 1548.6 Q1097.89 1545.54 1105.88 1545.54 L1114.09 1545.54 L1114.09 1544.97 Q1114.09 1540.93 1111.42 1538.73 Q1108.78 1536.5 1103.97 1536.5 Q1100.92 1536.5 1098.02 1537.23 Q1095.12 1537.97 1092.45 1539.43 L1092.45 1534.02 Q1095.66 1532.78 1098.69 1532.17 Q1101.71 1531.54 1104.58 1531.54 Q1112.31 1531.54 1116.13 1535.55 Q1119.95 1539.56 1119.95 1547.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1132.01 1532.4 L1137.87 1532.4 L1137.87 1568.04 L1132.01 1568.04 L1132.01 1532.4 M1132.01 1518.52 L1137.87 1518.52 L1137.87 1525.93 L1132.01 1525.93 L1132.01 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1179.75 1546.53 L1179.75 1568.04 L1173.9 1568.04 L1173.9 1546.72 Q1173.9 1541.66 1171.93 1539.14 Q1169.95 1536.63 1166.01 1536.63 Q1161.26 1536.63 1158.53 1539.65 Q1155.79 1542.68 1155.79 1547.9 L1155.79 1568.04 L1149.9 1568.04 L1149.9 1532.4 L1155.79 1532.4 L1155.79 1537.93 Q1157.89 1534.72 1160.72 1533.13 Q1163.59 1531.54 1167.31 1531.54 Q1173.45 1531.54 1176.6 1535.36 Q1179.75 1539.14 1179.75 1546.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1191.44 1532.4 L1197.29 1532.4 L1197.29 1568.04 L1191.44 1568.04 L1191.44 1532.4 M1191.44 1518.52 L1197.29 1518.52 L1197.29 1525.93 L1191.44 1525.93 L1191.44 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1239.18 1546.53 L1239.18 1568.04 L1233.32 1568.04 L1233.32 1546.72 Q1233.32 1541.66 1231.35 1539.14 Q1229.38 1536.63 1225.43 1536.63 Q1220.69 1536.63 1217.95 1539.65 Q1215.21 1542.68 1215.21 1547.9 L1215.21 1568.04 L1209.32 1568.04 L1209.32 1532.4 L1215.21 1532.4 L1215.21 1537.93 Q1217.31 1534.72 1220.15 1533.13 Q1223.01 1531.54 1226.73 1531.54 Q1232.88 1531.54 1236.03 1535.36 Q1239.18 1539.14 1239.18 1546.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1274.32 1549.81 Q1274.32 1543.44 1271.68 1539.94 Q1269.07 1536.44 1264.32 1536.44 Q1259.61 1536.44 1256.97 1539.94 Q1254.36 1543.44 1254.36 1549.81 Q1254.36 1556.14 1256.97 1559.64 Q1259.61 1563.14 1264.32 1563.14 Q1269.07 1563.14 1271.68 1559.64 Q1274.32 1556.14 1274.32 1549.81 M1280.17 1563.62 Q1280.17 1572.72 1276.13 1577.15 Q1272.09 1581.6 1263.75 1581.6 Q1260.66 1581.6 1257.93 1581.13 Q1255.19 1580.68 1252.61 1579.72 L1252.61 1574.03 Q1255.19 1575.43 1257.7 1576.1 Q1260.22 1576.76 1262.83 1576.76 Q1268.59 1576.76 1271.45 1573.74 Q1274.32 1570.75 1274.32 1564.67 L1274.32 1561.77 Q1272.5 1564.92 1269.67 1566.48 Q1266.84 1568.04 1262.89 1568.04 Q1256.33 1568.04 1252.32 1563.05 Q1248.31 1558.05 1248.31 1549.81 Q1248.31 1541.53 1252.32 1536.53 Q1256.33 1531.54 1262.89 1531.54 Q1266.84 1531.54 1269.67 1533.1 Q1272.5 1534.66 1274.32 1537.81 L1274.32 1532.4 L1280.17 1532.4 L1280.17 1563.62 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1313.21 1520.52 L1343.26 1520.52 L1343.26 1525.93 L1319.64 1525.93 L1319.64 1540 L1342.27 1540 L1342.27 1545.41 L1319.64 1545.41 L1319.64 1562.63 L1343.83 1562.63 L1343.83 1568.04 L1313.21 1568.04 L1313.21 1520.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1359.81 1562.7 L1359.81 1581.6 L1353.92 1581.6 L1353.92 1532.4 L1359.81 1532.4 L1359.81 1537.81 Q1361.66 1534.62 1364.46 1533.1 Q1367.29 1531.54 1371.2 1531.54 Q1377.7 1531.54 1381.74 1536.69 Q1385.81 1541.85 1385.81 1550.25 Q1385.81 1558.65 1381.74 1563.81 Q1377.7 1568.97 1371.2 1568.97 Q1367.29 1568.97 1364.46 1567.44 Q1361.66 1565.88 1359.81 1562.7 M1379.73 1550.25 Q1379.73 1543.79 1377.06 1540.13 Q1374.42 1536.44 1369.77 1536.44 Q1365.12 1536.44 1362.45 1540.13 Q1359.81 1543.79 1359.81 1550.25 Q1359.81 1556.71 1362.45 1560.4 Q1365.12 1564.07 1369.77 1564.07 Q1374.42 1564.07 1377.06 1560.4 Q1379.73 1556.71 1379.73 1550.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1395.52 1532.4 L1401.38 1532.4 L1401.38 1568.04 L1395.52 1568.04 L1395.52 1532.4 M1395.52 1518.52 L1401.38 1518.52 L1401.38 1525.93 L1395.52 1525.93 L1395.52 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1436.36 1533.45 L1436.36 1538.98 Q1433.87 1537.71 1431.2 1537.07 Q1428.53 1536.44 1425.66 1536.44 Q1421.3 1536.44 1419.11 1537.77 Q1416.94 1539.11 1416.94 1541.79 Q1416.94 1543.82 1418.5 1545 Q1420.06 1546.15 1424.77 1547.2 L1426.78 1547.64 Q1433.01 1548.98 1435.62 1551.43 Q1438.27 1553.85 1438.27 1558.21 Q1438.27 1563.17 1434.32 1566.07 Q1430.4 1568.97 1423.53 1568.97 Q1420.67 1568.97 1417.55 1568.39 Q1414.46 1567.85 1411.02 1566.74 L1411.02 1560.69 Q1414.27 1562.38 1417.42 1563.24 Q1420.57 1564.07 1423.66 1564.07 Q1427.79 1564.07 1430.02 1562.66 Q1432.25 1561.23 1432.25 1558.65 Q1432.25 1556.27 1430.63 1554.99 Q1429.04 1553.72 1423.59 1552.54 L1421.56 1552.07 Q1416.11 1550.92 1413.69 1548.56 Q1411.28 1546.18 1411.28 1542.04 Q1411.28 1537.01 1414.84 1534.27 Q1418.41 1531.54 1424.96 1531.54 Q1428.21 1531.54 1431.07 1532.01 Q1433.94 1532.49 1436.36 1533.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1461.41 1536.5 Q1456.7 1536.5 1453.96 1540.19 Q1451.22 1543.85 1451.22 1550.25 Q1451.22 1556.65 1453.93 1560.34 Q1456.66 1564 1461.41 1564 Q1466.08 1564 1468.82 1560.31 Q1471.56 1556.62 1471.56 1550.25 Q1471.56 1543.92 1468.82 1540.23 Q1466.08 1536.5 1461.41 1536.5 M1461.41 1531.54 Q1469.04 1531.54 1473.4 1536.5 Q1477.77 1541.47 1477.77 1550.25 Q1477.77 1559 1473.4 1564 Q1469.04 1568.97 1461.41 1568.97 Q1453.73 1568.97 1449.37 1564 Q1445.05 1559 1445.05 1550.25 Q1445.05 1541.47 1449.37 1536.5 Q1453.73 1531.54 1461.41 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1510.93 1537.81 L1510.93 1518.52 L1516.79 1518.52 L1516.79 1568.04 L1510.93 1568.04 L1510.93 1562.7 Q1509.08 1565.88 1506.25 1567.44 Q1503.45 1568.97 1499.5 1568.97 Q1493.04 1568.97 1488.97 1563.81 Q1484.93 1558.65 1484.93 1550.25 Q1484.93 1541.85 1488.97 1536.69 Q1493.04 1531.54 1499.5 1531.54 Q1503.45 1531.54 1506.25 1533.1 Q1509.08 1534.62 1510.93 1537.81 M1490.97 1550.25 Q1490.97 1556.71 1493.62 1560.4 Q1496.29 1564.07 1500.94 1564.07 Q1505.58 1564.07 1508.26 1560.4 Q1510.93 1556.71 1510.93 1550.25 Q1510.93 1543.79 1508.26 1540.13 Q1505.58 1536.44 1500.94 1536.44 Q1496.29 1536.44 1493.62 1540.13 Q1490.97 1543.79 1490.97 1550.25 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1559.34 1548.76 L1559.34 1551.62 L1532.42 1551.62 Q1532.8 1557.67 1536.04 1560.85 Q1539.32 1564 1545.15 1564 Q1548.52 1564 1551.67 1563.17 Q1554.85 1562.35 1557.97 1560.69 L1557.97 1566.23 Q1554.82 1567.57 1551.51 1568.27 Q1548.2 1568.97 1544.8 1568.97 Q1536.27 1568.97 1531.27 1564 Q1526.3 1559.04 1526.3 1550.57 Q1526.3 1541.82 1531.01 1536.69 Q1535.76 1531.54 1543.78 1531.54 Q1550.97 1531.54 1555.14 1536.18 Q1559.34 1540.8 1559.34 1548.76 M1553.49 1547.04 Q1553.42 1542.23 1550.78 1539.37 Q1548.17 1536.5 1543.84 1536.5 Q1538.94 1536.5 1535.98 1539.27 Q1533.05 1542.04 1532.61 1547.07 L1553.49 1547.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  235.283,1389.14 2352.76,1389.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  235.283,1037.65 2352.76,1037.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  235.283,686.164 2352.76,686.164 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  235.283,334.674 2352.76,334.674 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,1423.18 235.283,123.472 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,1389.14 254.18,1389.14 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,1037.65 254.18,1037.65 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,686.164 254.18,686.164 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  235.283,334.674 254.18,334.674 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M187.338 1374.94 Q183.727 1374.94 181.899 1378.51 Q180.093 1382.05 180.093 1389.18 Q180.093 1396.28 181.899 1399.85 Q183.727 1403.39 187.338 1403.39 Q190.973 1403.39 192.778 1399.85 Q194.607 1396.28 194.607 1389.18 Q194.607 1382.05 192.778 1378.51 Q190.973 1374.94 187.338 1374.94 M187.338 1371.24 Q193.149 1371.24 196.204 1375.84 Q199.283 1380.43 199.283 1389.18 Q199.283 1397.9 196.204 1402.51 Q193.149 1407.09 187.338 1407.09 Q181.528 1407.09 178.45 1402.51 Q175.394 1397.9 175.394 1389.18 Q175.394 1380.43 178.45 1375.84 Q181.528 1371.24 187.338 1371.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M121.043 1051 L137.362 1051 L137.362 1054.93 L115.418 1054.93 L115.418 1051 Q118.08 1048.24 122.663 1043.61 Q127.269 1038.96 128.45 1037.62 Q130.695 1035.1 131.575 1033.36 Q132.478 1031.6 132.478 1029.91 Q132.478 1027.16 130.533 1025.42 Q128.612 1023.68 125.51 1023.68 Q123.311 1023.68 120.857 1024.45 Q118.427 1025.21 115.649 1026.76 L115.649 1022.04 Q118.473 1020.91 120.927 1020.33 Q123.38 1019.75 125.418 1019.75 Q130.788 1019.75 133.982 1022.43 Q137.177 1025.12 137.177 1029.61 Q137.177 1031.74 136.367 1033.66 Q135.579 1035.56 133.473 1038.15 Q132.894 1038.82 129.792 1042.04 Q126.691 1045.23 121.043 1051 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M157.177 1023.45 Q153.566 1023.45 151.737 1027.02 Q149.931 1030.56 149.931 1037.69 Q149.931 1044.79 151.737 1048.36 Q153.566 1051.9 157.177 1051.9 Q160.811 1051.9 162.616 1048.36 Q164.445 1044.79 164.445 1037.69 Q164.445 1030.56 162.616 1027.02 Q160.811 1023.45 157.177 1023.45 M157.177 1019.75 Q162.987 1019.75 166.042 1024.35 Q169.121 1028.94 169.121 1037.69 Q169.121 1046.41 166.042 1051.02 Q162.987 1055.6 157.177 1055.6 Q151.366 1055.6 148.288 1051.02 Q145.232 1046.41 145.232 1037.69 Q145.232 1028.94 148.288 1024.35 Q151.366 1019.75 157.177 1019.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M187.338 1023.45 Q183.727 1023.45 181.899 1027.02 Q180.093 1030.56 180.093 1037.69 Q180.093 1044.79 181.899 1048.36 Q183.727 1051.9 187.338 1051.9 Q190.973 1051.9 192.778 1048.36 Q194.607 1044.79 194.607 1037.69 Q194.607 1030.56 192.778 1027.02 Q190.973 1023.45 187.338 1023.45 M187.338 1019.75 Q193.149 1019.75 196.204 1024.35 Q199.283 1028.94 199.283 1037.69 Q199.283 1046.41 196.204 1051.02 Q193.149 1055.6 187.338 1055.6 Q181.528 1055.6 178.45 1051.02 Q175.394 1046.41 175.394 1037.69 Q175.394 1028.94 178.45 1024.35 Q181.528 1019.75 187.338 1019.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M129.862 672.958 L118.056 691.407 L129.862 691.407 L129.862 672.958 M128.635 668.884 L134.515 668.884 L134.515 691.407 L139.445 691.407 L139.445 695.296 L134.515 695.296 L134.515 703.444 L129.862 703.444 L129.862 695.296 L114.26 695.296 L114.26 690.782 L128.635 668.884 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M157.177 671.962 Q153.566 671.962 151.737 675.527 Q149.931 679.069 149.931 686.199 Q149.931 693.305 151.737 696.87 Q153.566 700.411 157.177 700.411 Q160.811 700.411 162.616 696.87 Q164.445 693.305 164.445 686.199 Q164.445 679.069 162.616 675.527 Q160.811 671.962 157.177 671.962 M157.177 668.259 Q162.987 668.259 166.042 672.865 Q169.121 677.449 169.121 686.199 Q169.121 694.925 166.042 699.532 Q162.987 704.115 157.177 704.115 Q151.366 704.115 148.288 699.532 Q145.232 694.925 145.232 686.199 Q145.232 677.449 148.288 672.865 Q151.366 668.259 157.177 668.259 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M187.338 671.962 Q183.727 671.962 181.899 675.527 Q180.093 679.069 180.093 686.199 Q180.093 693.305 181.899 696.87 Q183.727 700.411 187.338 700.411 Q190.973 700.411 192.778 696.87 Q194.607 693.305 194.607 686.199 Q194.607 679.069 192.778 675.527 Q190.973 671.962 187.338 671.962 M187.338 668.259 Q193.149 668.259 196.204 672.865 Q199.283 677.449 199.283 686.199 Q199.283 694.925 196.204 699.532 Q193.149 704.115 187.338 704.115 Q181.528 704.115 178.45 699.532 Q175.394 694.925 175.394 686.199 Q175.394 677.449 178.45 672.865 Q181.528 668.259 187.338 668.259 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M127.593 332.811 Q124.445 332.811 122.593 334.964 Q120.765 337.116 120.765 340.866 Q120.765 344.593 122.593 346.769 Q124.445 348.922 127.593 348.922 Q130.742 348.922 132.57 346.769 Q134.422 344.593 134.422 340.866 Q134.422 337.116 132.57 334.964 Q130.742 332.811 127.593 332.811 M136.876 318.158 L136.876 322.417 Q135.117 321.584 133.311 321.144 Q131.529 320.704 129.769 320.704 Q125.14 320.704 122.686 323.829 Q120.255 326.954 119.908 333.274 Q121.274 331.26 123.334 330.195 Q125.394 329.107 127.871 329.107 Q133.08 329.107 136.089 332.278 Q139.121 335.427 139.121 340.866 Q139.121 346.19 135.973 349.408 Q132.825 352.625 127.593 352.625 Q121.598 352.625 118.427 348.042 Q115.256 343.436 115.256 334.709 Q115.256 326.515 119.144 321.653 Q123.033 316.769 129.584 316.769 Q131.343 316.769 133.126 317.116 Q134.931 317.464 136.876 318.158 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M157.177 320.473 Q153.566 320.473 151.737 324.038 Q149.931 327.579 149.931 334.709 Q149.931 341.815 151.737 345.38 Q153.566 348.922 157.177 348.922 Q160.811 348.922 162.616 345.38 Q164.445 341.815 164.445 334.709 Q164.445 327.579 162.616 324.038 Q160.811 320.473 157.177 320.473 M157.177 316.769 Q162.987 316.769 166.042 321.376 Q169.121 325.959 169.121 334.709 Q169.121 343.436 166.042 348.042 Q162.987 352.625 157.177 352.625 Q151.366 352.625 148.288 348.042 Q145.232 343.436 145.232 334.709 Q145.232 325.959 148.288 321.376 Q151.366 316.769 157.177 316.769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M187.338 320.473 Q183.727 320.473 181.899 324.038 Q180.093 327.579 180.093 334.709 Q180.093 341.815 181.899 345.38 Q183.727 348.922 187.338 348.922 Q190.973 348.922 192.778 345.38 Q194.607 341.815 194.607 334.709 Q194.607 327.579 192.778 324.038 Q190.973 320.473 187.338 320.473 M187.338 316.769 Q193.149 316.769 196.204 321.376 Q199.283 325.959 199.283 334.709 Q199.283 343.436 196.204 348.042 Q193.149 352.625 187.338 352.625 Q181.528 352.625 178.45 348.042 Q175.394 343.436 175.394 334.709 Q175.394 325.959 178.45 321.376 Q181.528 316.769 187.338 316.769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M20.8447 1141.26 Q20.8447 1148.27 26.0645 1152.4 Q31.2844 1156.51 40.2919 1156.51 Q49.2675 1156.51 54.4874 1152.4 Q59.7073 1148.27 59.7073 1141.26 Q59.7073 1134.26 54.4874 1130.19 Q49.2675 1126.08 40.2919 1126.08 Q31.2844 1126.08 26.0645 1130.19 Q20.8447 1134.26 20.8447 1141.26 M63.1448 1132.26 L72.4069 1123.79 L72.4069 1131.56 L64.7999 1138.59 Q64.8635 1139.64 64.8954 1140.21 Q64.9272 1140.75 64.9272 1141.26 Q64.9272 1151.29 58.2432 1157.31 Q51.5274 1163.29 40.2919 1163.29 Q29.0246 1163.29 22.3406 1157.31 Q15.6248 1151.29 15.6248 1141.26 Q15.6248 1131.27 22.3406 1125.29 Q29.0246 1119.3 40.2919 1119.3 Q48.5673 1119.3 54.4556 1122.64 Q60.3439 1125.95 63.1448 1132.26 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M43.5384 1110.64 L43.5384 1093.49 L48.7583 1093.49 L48.7583 1110.64 L43.5384 1110.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M16.4842 1083.91 L16.4842 1056.6 L21.895 1056.6 L21.895 1077.48 L35.8996 1077.48 L35.8996 1058.64 L41.3104 1058.64 L41.3104 1077.48 L64.0042 1077.48 L64.0042 1083.91 L16.4842 1083.91 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M49.9359 1050.84 L28.3562 1050.84 L28.3562 1044.98 L49.7131 1044.98 Q54.7739 1044.98 57.3202 1043.01 Q59.8346 1041.04 59.8346 1037.09 Q59.8346 1032.35 56.8109 1029.61 Q53.7872 1026.84 48.5673 1026.84 L28.3562 1026.84 L28.3562 1020.98 L64.0042 1020.98 L64.0042 1026.84 L58.5296 1026.84 Q61.7762 1028.97 63.3676 1031.81 Q64.9272 1034.61 64.9272 1038.33 Q64.9272 1044.47 61.1078 1047.66 Q57.2883 1050.84 49.9359 1050.84 M27.4968 1036.1 L27.4968 1036.1 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M42.4881 979.288 L64.0042 979.288 L64.0042 985.145 L42.679 985.145 Q37.6183 985.145 35.1038 987.118 Q32.5894 989.092 32.5894 993.038 Q32.5894 997.781 35.6131 1000.52 Q38.6368 1003.26 43.8567 1003.26 L64.0042 1003.26 L64.0042 1009.14 L28.3562 1009.14 L28.3562 1003.26 L33.8944 1003.26 Q30.6797 1001.15 29.0883 998.322 Q27.4968 995.457 27.4968 991.733 Q27.4968 985.59 31.3163 982.439 Q35.1038 979.288 42.4881 979.288 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M29.7248 941.954 L35.1993 941.954 Q33.8307 944.436 33.1623 946.951 Q32.4621 949.433 32.4621 951.98 Q32.4621 957.677 36.0905 960.828 Q39.6872 963.979 46.212 963.979 Q52.7369 963.979 56.3653 960.828 Q59.9619 957.677 59.9619 951.98 Q59.9619 949.433 59.2935 946.951 Q58.5933 944.436 57.2247 941.954 L62.6355 941.954 Q63.7814 944.404 64.3543 947.046 Q64.9272 949.656 64.9272 952.616 Q64.9272 960.669 59.8664 965.411 Q54.8057 970.154 46.212 970.154 Q37.491 970.154 32.4939 965.379 Q27.4968 960.573 27.4968 952.234 Q27.4968 949.529 28.0697 946.951 Q28.6108 944.373 29.7248 941.954 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M18.2347 925.976 L28.3562 925.976 L28.3562 913.913 L32.9077 913.913 L32.9077 925.976 L52.2594 925.976 Q56.6199 925.976 57.8613 924.798 Q59.1026 923.588 59.1026 919.928 L59.1026 913.913 L64.0042 913.913 L64.0042 919.928 Q64.0042 926.708 61.4897 929.286 Q58.9434 931.864 52.2594 931.864 L32.9077 931.864 L32.9077 936.161 L28.3562 936.161 L28.3562 931.864 L18.2347 931.864 L18.2347 925.976 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M28.3562 906.21 L28.3562 900.354 L64.0042 900.354 L64.0042 906.21 L28.3562 906.21 M14.479 906.21 L14.479 900.354 L21.895 900.354 L21.895 906.21 L14.479 906.21 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M32.4621 874.286 Q32.4621 878.997 36.1542 881.734 Q39.8145 884.471 46.212 884.471 Q52.6095 884.471 56.3017 881.766 Q59.9619 879.029 59.9619 874.286 Q59.9619 869.607 56.2698 866.87 Q52.5777 864.133 46.212 864.133 Q39.8781 864.133 36.186 866.87 Q32.4621 869.607 32.4621 874.286 M27.4968 874.286 Q27.4968 866.647 32.4621 862.287 Q37.4273 857.926 46.212 857.926 Q54.9649 857.926 59.9619 862.287 Q64.9272 866.647 64.9272 874.286 Q64.9272 881.957 59.9619 886.317 Q54.9649 890.646 46.212 890.646 Q37.4273 890.646 32.4621 886.317 Q27.4968 881.957 27.4968 874.286 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M42.4881 818.586 L64.0042 818.586 L64.0042 824.443 L42.679 824.443 Q37.6183 824.443 35.1038 826.416 Q32.5894 828.389 32.5894 832.336 Q32.5894 837.079 35.6131 839.816 Q38.6368 842.553 43.8567 842.553 L64.0042 842.553 L64.0042 848.441 L28.3562 848.441 L28.3562 842.553 L33.8944 842.553 Q30.6797 840.452 29.0883 837.62 Q27.4968 834.755 27.4968 831.031 Q27.4968 824.888 31.3163 821.737 Q35.1038 818.586 42.4881 818.586 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M16.4842 785.93 L16.4842 755.884 L21.895 755.884 L21.895 779.501 L35.9632 779.501 L35.9632 756.871 L41.3741 756.871 L41.3741 779.501 L58.5933 779.501 L58.5933 755.311 L64.0042 755.311 L64.0042 785.93 L16.4842 785.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M33.8307 724.342 Q33.2578 725.329 33.0032 726.506 Q32.7167 727.652 32.7167 729.052 Q32.7167 734.018 35.9632 736.691 Q39.1779 739.333 45.2253 739.333 L64.0042 739.333 L64.0042 745.221 L28.3562 745.221 L28.3562 739.333 L33.8944 739.333 Q30.6479 737.487 29.0883 734.527 Q27.4968 731.567 27.4968 727.334 Q27.4968 726.729 27.5923 725.997 Q27.656 725.265 27.8151 724.374 L33.8307 724.342 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M33.8307 698.688 Q33.2578 699.675 33.0032 700.852 Q32.7167 701.998 32.7167 703.399 Q32.7167 708.364 35.9632 711.038 Q39.1779 713.679 45.2253 713.679 L64.0042 713.679 L64.0042 719.568 L28.3562 719.568 L28.3562 713.679 L33.8944 713.679 Q30.6479 711.833 29.0883 708.873 Q27.4968 705.913 27.4968 701.68 Q27.4968 701.075 27.5923 700.343 Q27.656 699.611 27.8151 698.72 L33.8307 698.688 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M32.4621 680.164 Q32.4621 684.874 36.1542 687.612 Q39.8145 690.349 46.212 690.349 Q52.6095 690.349 56.3017 687.644 Q59.9619 684.906 59.9619 680.164 Q59.9619 675.485 56.2698 672.748 Q52.5777 670.011 46.212 670.011 Q39.8781 670.011 36.186 672.748 Q32.4621 675.485 32.4621 680.164 M27.4968 680.164 Q27.4968 672.525 32.4621 668.165 Q37.4273 663.804 46.212 663.804 Q54.9649 663.804 59.9619 668.165 Q64.9272 672.525 64.9272 680.164 Q64.9272 687.835 59.9619 692.195 Q54.9649 696.524 46.212 696.524 Q37.4273 696.524 32.4621 692.195 Q27.4968 687.835 27.4968 680.164 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M33.8307 633.44 Q33.2578 634.426 33.0032 635.604 Q32.7167 636.75 32.7167 638.15 Q32.7167 643.115 35.9632 645.789 Q39.1779 648.431 45.2253 648.431 L64.0042 648.431 L64.0042 654.319 L28.3562 654.319 L28.3562 648.431 L33.8944 648.431 Q30.6479 646.585 29.0883 643.625 Q27.4968 640.665 27.4968 636.431 Q27.4968 635.827 27.5923 635.095 Q27.656 634.363 27.8151 633.471 L33.8307 633.44 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M14.5426 592.508 Q21.8632 596.773 29.0246 598.842 Q36.186 600.911 43.5384 600.911 Q50.8908 600.911 58.1159 598.842 Q65.3091 596.741 72.5979 592.508 L72.5979 597.601 Q65.1182 602.375 57.8931 604.762 Q50.668 607.117 43.5384 607.117 Q36.4406 607.117 29.2474 604.762 Q22.0542 602.407 14.5426 597.601 L14.5426 592.508 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M41.7242 558.356 Q42.4244 556.287 44.7161 554.346 Q47.0077 552.372 51.0181 550.399 L64.0042 543.874 L64.0042 550.781 L51.8138 556.86 Q47.0395 559.215 45.48 561.443 Q43.9204 563.64 43.9204 567.459 L43.9204 574.461 L64.0042 574.461 L64.0042 580.891 L16.4842 580.891 L16.4842 566.377 Q16.4842 558.229 19.8898 554.218 Q23.2955 550.208 30.1704 550.208 Q34.6582 550.208 37.6183 552.309 Q40.5784 554.378 41.7242 558.356 M21.7677 574.461 L38.6368 574.461 L38.6368 566.377 Q38.6368 561.73 36.5043 559.375 Q34.34 556.987 30.1704 556.987 Q26.0009 556.987 23.9002 559.375 Q21.7677 561.73 21.7677 566.377 L21.7677 574.461 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M16.4842 535.599 L16.4842 526.018 L48.8219 513.892 L16.4842 501.701 L16.4842 492.121 L64.0042 492.121 L64.0042 498.391 L22.277 498.391 L54.8694 510.645 L54.8694 517.106 L22.277 529.36 L64.0042 529.36 L64.0042 535.599 L16.4842 535.599 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M18.0438 450.871 L24.314 450.871 Q22.5634 454.531 21.704 457.778 Q20.8447 461.024 20.8447 464.048 Q20.8447 469.3 22.8817 472.164 Q24.9187 474.997 28.6745 474.997 Q31.8255 474.997 33.4488 473.119 Q35.0402 471.21 36.0269 465.926 L36.8226 462.043 Q38.1912 454.85 41.6605 451.444 Q45.098 448.007 50.8908 448.007 Q57.7976 448.007 61.3624 452.654 Q64.9272 457.269 64.9272 466.212 Q64.9272 469.586 64.1633 473.406 Q63.3994 477.193 61.9035 481.267 L55.2831 481.267 Q57.4793 477.352 58.5933 473.597 Q59.7073 469.841 59.7073 466.212 Q59.7073 460.706 57.543 457.714 Q55.3786 454.722 51.3682 454.722 Q47.8671 454.722 45.8937 456.887 Q43.9204 459.019 42.9337 463.921 L42.1698 467.836 Q40.7375 475.029 37.682 478.244 Q34.6264 481.458 29.1837 481.458 Q22.8817 481.458 19.2532 477.034 Q15.6248 472.578 15.6248 464.78 Q15.6248 461.438 16.2295 457.969 Q16.8343 454.5 18.0438 450.871 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M16.4842 437.981 L16.4842 407.934 L21.895 407.934 L21.895 431.551 L35.9632 431.551 L35.9632 408.921 L41.3741 408.921 L41.3741 431.551 L58.5933 431.551 L58.5933 407.362 L64.0042 407.362 L64.0042 437.981 L16.4842 437.981 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M14.5426 397.972 L14.5426 392.88 Q22.0542 388.105 29.2474 385.75 Q36.4406 383.363 43.5384 383.363 Q50.668 383.363 57.8931 385.75 Q65.1182 388.105 72.5979 392.88 L72.5979 397.972 Q65.3091 393.739 58.1159 391.67 Q50.8908 389.569 43.5384 389.569 Q36.186 389.569 29.0246 391.67 Q21.8632 393.739 14.5426 397.972 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M700.299 12.096 L751.462 12.096 L751.462 18.9825 L729.992 18.9825 L729.992 72.576 L721.768 72.576 L721.768 18.9825 L700.299 18.9825 L700.299 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M773.134 34.1734 Q771.878 33.4443 770.379 33.1202 Q768.921 32.7556 767.139 32.7556 Q760.819 32.7556 757.416 36.8875 Q754.054 40.9789 754.054 48.6757 L754.054 72.576 L746.56 72.576 L746.56 27.2059 L754.054 27.2059 L754.054 34.2544 Q756.404 30.1225 760.171 28.1376 Q763.938 26.1121 769.326 26.1121 Q770.096 26.1121 771.027 26.2337 Q771.959 26.3147 773.093 26.5172 L773.134 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M801.571 49.7694 Q792.538 49.7694 789.054 51.8354 Q785.57 53.9013 785.57 58.8839 Q785.57 62.8538 788.163 65.2034 Q790.796 67.5124 795.292 67.5124 Q801.49 67.5124 805.217 63.1374 Q808.984 58.7219 808.984 51.4303 L808.984 49.7694 L801.571 49.7694 M816.438 46.6907 L816.438 72.576 L808.984 72.576 L808.984 65.6895 Q806.432 69.8214 802.624 71.8063 Q798.817 73.7508 793.307 73.7508 Q786.34 73.7508 782.208 69.8619 Q778.116 65.9325 778.116 59.3701 Q778.116 51.7138 783.221 47.825 Q788.365 43.9361 798.533 43.9361 L808.984 43.9361 L808.984 43.2069 Q808.984 38.0623 805.582 35.2672 Q802.219 32.4315 796.102 32.4315 Q792.214 32.4315 788.527 33.3632 Q784.841 34.295 781.438 36.1584 L781.438 29.2718 Q785.53 27.692 789.378 26.9223 Q793.226 26.1121 796.872 26.1121 Q806.716 26.1121 811.577 31.2163 Q816.438 36.3204 816.438 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M831.791 27.2059 L839.245 27.2059 L839.245 72.576 L831.791 72.576 L831.791 27.2059 M831.791 9.54393 L839.245 9.54393 L839.245 18.9825 L831.791 18.9825 L831.791 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M892.555 45.1919 L892.555 72.576 L885.101 72.576 L885.101 45.4349 Q885.101 38.994 882.589 35.7938 Q880.078 32.5936 875.055 32.5936 Q869.019 32.5936 865.535 36.4419 Q862.051 40.2903 862.051 46.9338 L862.051 72.576 L854.557 72.576 L854.557 27.2059 L862.051 27.2059 L862.051 34.2544 Q864.725 30.163 868.33 28.1376 Q871.976 26.1121 876.715 26.1121 Q884.534 26.1121 888.544 30.9732 Q892.555 35.7938 892.555 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M907.421 27.2059 L914.875 27.2059 L914.875 72.576 L907.421 72.576 L907.421 27.2059 M907.421 9.54393 L914.875 9.54393 L914.875 18.9825 L907.421 18.9825 L907.421 9.54393 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M968.185 45.1919 L968.185 72.576 L960.731 72.576 L960.731 45.4349 Q960.731 38.994 958.22 35.7938 Q955.708 32.5936 950.685 32.5936 Q944.649 32.5936 941.165 36.4419 Q937.682 40.2903 937.682 46.9338 L937.682 72.576 L930.187 72.576 L930.187 27.2059 L937.682 27.2059 L937.682 34.2544 Q940.355 30.163 943.96 28.1376 Q947.606 26.1121 952.346 26.1121 Q960.164 26.1121 964.175 30.9732 Q968.185 35.7938 968.185 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1012.91 49.3643 Q1012.91 41.2625 1009.54 36.8065 Q1006.22 32.3505 1000.19 32.3505 Q994.192 32.3505 990.829 36.8065 Q987.508 41.2625 987.508 49.3643 Q987.508 57.4256 990.829 61.8816 Q994.192 66.3376 1000.19 66.3376 Q1006.22 66.3376 1009.54 61.8816 Q1012.91 57.4256 1012.91 49.3643 M1020.36 66.9452 Q1020.36 78.5308 1015.22 84.1616 Q1010.07 89.8329 999.458 89.8329 Q995.529 89.8329 992.045 89.2252 Q988.561 88.6581 985.28 87.4428 L985.28 80.1917 Q988.561 81.9741 991.761 82.8248 Q994.961 83.6755 998.283 83.6755 Q1005.62 83.6755 1009.26 79.8271 Q1012.91 76.0193 1012.91 68.282 L1012.91 64.5957 Q1010.6 68.6061 1006.99 70.5911 Q1003.39 72.576 998.364 72.576 Q990.019 72.576 984.915 66.2161 Q979.811 59.8562 979.811 49.3643 Q979.811 38.832 984.915 32.472 Q990.019 26.1121 998.364 26.1121 Q1003.39 26.1121 1006.99 28.0971 Q1010.6 30.082 1012.91 34.0924 L1012.91 27.2059 L1020.36 27.2059 L1020.36 66.9452 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1107.7 16.7545 L1107.7 25.383 Q1103.57 21.5346 1098.87 19.6307 Q1094.21 17.7268 1088.94 17.7268 Q1078.57 17.7268 1073.06 24.0867 Q1067.55 30.4061 1067.55 42.3968 Q1067.55 54.3469 1073.06 60.7069 Q1078.57 67.0263 1088.94 67.0263 Q1094.21 67.0263 1098.87 65.1223 Q1103.57 63.2184 1107.7 59.3701 L1107.7 67.9175 Q1103.4 70.8341 1098.58 72.2924 Q1093.8 73.7508 1088.46 73.7508 Q1074.72 73.7508 1066.82 65.3654 Q1058.93 56.9395 1058.93 42.3968 Q1058.93 27.8135 1066.82 19.4281 Q1074.72 11.0023 1088.46 11.0023 Q1093.88 11.0023 1098.66 12.4606 Q1103.49 13.8784 1107.7 16.7545 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1119.24 54.671 L1119.24 27.2059 L1126.7 27.2059 L1126.7 54.3874 Q1126.7 60.8284 1129.21 64.0691 Q1131.72 67.2693 1136.74 67.2693 Q1142.78 67.2693 1146.26 63.421 Q1149.79 59.5726 1149.79 52.9291 L1149.79 27.2059 L1157.24 27.2059 L1157.24 72.576 L1149.79 72.576 L1149.79 65.6084 Q1147.07 69.7404 1143.47 71.7658 Q1139.9 73.7508 1135.16 73.7508 Q1127.34 73.7508 1123.29 68.8897 Q1119.24 64.0286 1119.24 54.671 M1138 26.1121 L1138 26.1121 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1198.88 34.1734 Q1197.63 33.4443 1196.13 33.1202 Q1194.67 32.7556 1192.89 32.7556 Q1186.57 32.7556 1183.17 36.8875 Q1179.8 40.9789 1179.8 48.6757 L1179.8 72.576 L1172.31 72.576 L1172.31 27.2059 L1179.8 27.2059 L1179.8 34.2544 Q1182.15 30.1225 1185.92 28.1376 Q1189.69 26.1121 1195.08 26.1121 Q1195.85 26.1121 1196.78 26.2337 Q1197.71 26.3147 1198.84 26.5172 L1198.88 34.1734 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1201.35 27.2059 L1209.25 27.2059 L1223.43 65.2844 L1237.61 27.2059 L1245.51 27.2059 L1228.5 72.576 L1218.37 72.576 L1201.35 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1294.61 48.0275 L1294.61 51.6733 L1260.34 51.6733 Q1260.82 59.3701 1264.95 63.421 Q1269.13 67.4314 1276.54 67.4314 Q1280.83 67.4314 1284.84 66.3781 Q1288.89 65.3249 1292.86 63.2184 L1292.86 70.267 Q1288.85 71.9684 1284.64 72.8596 Q1280.43 73.7508 1276.09 73.7508 Q1265.24 73.7508 1258.88 67.4314 Q1252.56 61.1119 1252.56 50.3365 Q1252.56 39.1965 1258.55 32.6746 Q1264.59 26.1121 1274.8 26.1121 Q1283.95 26.1121 1289.26 32.0264 Q1294.61 37.9003 1294.61 48.0275 M1287.15 45.84 Q1287.07 39.7232 1283.71 36.0774 Q1280.39 32.4315 1274.88 32.4315 Q1268.64 32.4315 1264.87 35.9558 Q1261.15 39.4801 1260.58 45.8805 L1287.15 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1329.44 46.5287 L1351.28 46.5287 L1351.28 53.1722 L1329.44 53.1722 L1329.44 46.5287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1389.84 12.096 L1400.86 12.096 L1427.68 62.6918 L1427.68 12.096 L1435.62 12.096 L1435.62 72.576 L1424.6 72.576 L1397.78 21.9802 L1397.78 72.576 L1389.84 72.576 L1389.84 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1472.2 49.7694 Q1463.16 49.7694 1459.68 51.8354 Q1456.2 53.9013 1456.2 58.8839 Q1456.2 62.8538 1458.79 65.2034 Q1461.42 67.5124 1465.92 67.5124 Q1472.12 67.5124 1475.84 63.1374 Q1479.61 58.7219 1479.61 51.4303 L1479.61 49.7694 L1472.2 49.7694 M1487.07 46.6907 L1487.07 72.576 L1479.61 72.576 L1479.61 65.6895 Q1477.06 69.8214 1473.25 71.8063 Q1469.44 73.7508 1463.93 73.7508 Q1456.97 73.7508 1452.84 69.8619 Q1448.74 65.9325 1448.74 59.3701 Q1448.74 51.7138 1453.85 47.825 Q1458.99 43.9361 1469.16 43.9361 L1479.61 43.9361 L1479.61 43.2069 Q1479.61 38.0623 1476.21 35.2672 Q1472.85 32.4315 1466.73 32.4315 Q1462.84 32.4315 1459.15 33.3632 Q1455.47 34.295 1452.07 36.1584 L1452.07 29.2718 Q1456.16 27.692 1460.01 26.9223 Q1463.85 26.1121 1467.5 26.1121 Q1477.34 26.1121 1482.2 31.2163 Q1487.07 36.3204 1487.07 46.6907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1502.42 27.2059 L1509.87 27.2059 L1509.87 72.576 L1502.42 72.576 L1502.42 27.2059 M1506.14 26.1121 L1506.14 26.1121 M1509.95 9.70597 L1518.18 9.70597 L1518.18 17.8888 L1509.95 17.8888 L1509.95 9.70597 M1494.11 9.70597 L1502.34 9.70597 L1502.34 17.8888 L1494.11 17.8888 L1494.11 9.70597 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1520.12 27.2059 L1528.02 27.2059 L1542.2 65.2844 L1556.38 27.2059 L1564.28 27.2059 L1547.26 72.576 L1537.13 72.576 L1520.12 27.2059 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1613.37 48.0275 L1613.37 51.6733 L1579.1 51.6733 Q1579.59 59.3701 1583.72 63.421 Q1587.89 67.4314 1595.31 67.4314 Q1599.6 67.4314 1603.61 66.3781 Q1607.66 65.3249 1611.63 63.2184 L1611.63 70.267 Q1607.62 71.9684 1603.41 72.8596 Q1599.19 73.7508 1594.86 73.7508 Q1584 73.7508 1577.64 67.4314 Q1571.32 61.1119 1571.32 50.3365 Q1571.32 39.1965 1577.32 32.6746 Q1583.36 26.1121 1593.56 26.1121 Q1602.72 26.1121 1608.03 32.0264 Q1613.37 37.9003 1613.37 48.0275 M1605.92 45.84 Q1605.84 39.7232 1602.48 36.0774 Q1599.15 32.4315 1593.64 32.4315 Q1587.41 32.4315 1583.64 35.9558 Q1579.91 39.4801 1579.34 45.8805 L1605.92 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1672.52 20.1573 L1661.42 50.2555 L1683.66 50.2555 L1672.52 20.1573 M1667.9 12.096 L1677.17 12.096 L1700.22 72.576 L1691.72 72.576 L1686.21 57.061 L1658.95 57.061 L1653.44 72.576 L1644.81 72.576 L1667.9 12.096 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1738.59 49.3643 Q1738.59 41.2625 1735.22 36.8065 Q1731.9 32.3505 1725.87 32.3505 Q1719.87 32.3505 1716.51 36.8065 Q1713.19 41.2625 1713.19 49.3643 Q1713.19 57.4256 1716.51 61.8816 Q1719.87 66.3376 1725.87 66.3376 Q1731.9 66.3376 1735.22 61.8816 Q1738.59 57.4256 1738.59 49.3643 M1746.04 66.9452 Q1746.04 78.5308 1740.89 84.1616 Q1735.75 89.8329 1725.14 89.8329 Q1721.21 89.8329 1717.72 89.2252 Q1714.24 88.6581 1710.96 87.4428 L1710.96 80.1917 Q1714.24 81.9741 1717.44 82.8248 Q1720.64 83.6755 1723.96 83.6755 Q1731.29 83.6755 1734.94 79.8271 Q1738.59 76.0193 1738.59 68.282 L1738.59 64.5957 Q1736.28 68.6061 1732.67 70.5911 Q1729.07 72.576 1724.04 72.576 Q1715.7 72.576 1710.59 66.2161 Q1705.49 59.8562 1705.49 49.3643 Q1705.49 38.832 1710.59 32.472 Q1715.7 26.1121 1724.04 26.1121 Q1729.07 26.1121 1732.67 28.0971 Q1736.28 30.082 1738.59 34.0924 L1738.59 27.2059 L1746.04 27.2059 L1746.04 66.9452 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1800.2 48.0275 L1800.2 51.6733 L1765.93 51.6733 Q1766.42 59.3701 1770.55 63.421 Q1774.72 67.4314 1782.13 67.4314 Q1786.43 67.4314 1790.44 66.3781 Q1794.49 65.3249 1798.46 63.2184 L1798.46 70.267 Q1794.45 71.9684 1790.23 72.8596 Q1786.02 73.7508 1781.69 73.7508 Q1770.83 73.7508 1764.47 67.4314 Q1758.15 61.1119 1758.15 50.3365 Q1758.15 39.1965 1764.15 32.6746 Q1770.18 26.1121 1780.39 26.1121 Q1789.55 26.1121 1794.85 32.0264 Q1800.2 37.9003 1800.2 48.0275 M1792.75 45.84 Q1792.67 39.7232 1789.3 36.0774 Q1785.98 32.4315 1780.47 32.4315 Q1774.23 32.4315 1770.47 35.9558 Q1766.74 39.4801 1766.17 45.8805 L1792.75 45.84 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1850.15 45.1919 L1850.15 72.576 L1842.69 72.576 L1842.69 45.4349 Q1842.69 38.994 1840.18 35.7938 Q1837.67 32.5936 1832.65 32.5936 Q1826.61 32.5936 1823.13 36.4419 Q1819.64 40.2903 1819.64 46.9338 L1819.64 72.576 L1812.15 72.576 L1812.15 27.2059 L1819.64 27.2059 L1819.64 34.2544 Q1822.32 30.163 1825.92 28.1376 Q1829.57 26.1121 1834.31 26.1121 Q1842.13 26.1121 1846.14 30.9732 Q1850.15 35.7938 1850.15 45.1919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M1872.39 14.324 L1872.39 27.2059 L1887.74 27.2059 L1887.74 32.9987 L1872.39 32.9987 L1872.39 57.6282 Q1872.39 63.1779 1873.89 64.7578 Q1875.43 66.3376 1880.08 66.3376 L1887.74 66.3376 L1887.74 72.576 L1880.08 72.576 Q1871.46 72.576 1868.17 69.3758 Q1864.89 66.1351 1864.89 57.6282 L1864.89 32.9987 L1859.42 32.9987 L1859.42 27.2059 L1864.89 27.2059 L1864.89 14.324 L1872.39 14.324 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip842)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  295.211,201.974 311.321,166.198 327.431,160.256 343.541,168.202 359.651,199.485 375.76,241.465 391.87,279.862 407.98,322.061 424.09,366.142 440.2,411.79 \n",
       "  456.309,456.883 472.419,499.5 488.529,541.133 504.639,581.473 520.749,620.567 536.858,658.096 552.968,693.781 569.078,727.916 585.188,760.52 601.298,791.645 \n",
       "  617.407,821.287 633.517,849.467 649.627,876.281 665.737,901.779 681.847,926.047 697.957,949.123 714.066,971.052 730.176,991.889 746.286,1011.7 762.396,1030.54 \n",
       "  778.506,1048.44 794.615,1065.45 810.725,1081.61 826.835,1096.97 842.945,1111.56 859.055,1125.42 875.164,1138.6 891.274,1151.11 907.384,1163.01 923.494,1174.31 \n",
       "  939.604,1185.04 955.713,1195.24 971.823,1204.93 987.933,1214.13 1004.04,1222.88 1020.15,1231.19 1036.26,1239.08 1052.37,1246.58 1068.48,1253.71 1084.59,1260.48 \n",
       "  1100.7,1266.91 1116.81,1273.02 1132.92,1278.82 1149.03,1284.34 1165.14,1289.58 1181.25,1294.55 1197.36,1299.28 1213.47,1303.77 1229.58,1308.04 1245.69,1312.1 \n",
       "  1261.8,1315.95 1277.91,1319.61 1294.02,1323.08 1310.13,1326.39 1326.24,1329.52 1342.35,1332.5 1358.46,1335.33 1374.57,1338.02 1390.68,1340.58 1406.79,1343.01 \n",
       "  1422.9,1345.31 1439.01,1347.5 1455.12,1349.59 1471.23,1351.56 1487.34,1353.44 1503.45,1355.23 1519.56,1356.92 1535.67,1358.53 1551.78,1360.06 1567.89,1361.52 \n",
       "  1584,1362.9 1600.11,1364.21 1616.22,1365.46 1632.33,1366.64 1648.44,1367.77 1664.54,1368.84 1680.65,1369.85 1696.76,1370.82 1712.87,1371.73 1728.98,1372.6 \n",
       "  1745.09,1373.43 1761.2,1374.22 1777.31,1374.96 1793.42,1375.67 1809.53,1376.34 1825.64,1376.98 1841.75,1377.59 1857.86,1378.17 1873.97,1378.72 1890.08,1379.24 \n",
       "  1906.19,1379.73 1922.3,1380.2 1938.41,1380.65 1954.52,1381.08 1970.63,1381.48 1986.74,1381.86 2002.85,1382.23 2018.96,1382.57 2035.07,1382.9 2051.18,1383.21 \n",
       "  2067.29,1383.51 2083.4,1383.79 2099.51,1384.06 2115.62,1384.31 2131.73,1384.55 2147.84,1384.78 2163.95,1385 2180.06,1385.21 2196.17,1385.41 2212.28,1385.59 \n",
       "  2228.39,1385.77 2244.5,1385.94 2260.61,1386.1 2276.72,1386.25 2292.83,1386.4 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(\n",
    "    1:length(training_log[\"naive\"]),training_log[\"naive\"],\n",
    "    legend=false,\n",
    "    title=\"Training Curve - Naïve Agent\",\n",
    "    xlabel=\"Training Episode\",\n",
    "    ylabel=\"Q-Function Error (RMSE)\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
